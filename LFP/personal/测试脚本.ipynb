{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    " \n",
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()  # 第一句话，调用父类的构造函数\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.relu1=torch.nn.ReLU()\n",
    "        self.max_pooling1=torch.nn.MaxPool2d(2,1)\n",
    " \n",
    "        self.conv2 = torch.nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.relu2=torch.nn.ReLU()\n",
    "        self.max_pooling2=torch.nn.MaxPool2d(2,1)\n",
    " \n",
    "        self.dense1 = torch.nn.Linear(32 * 3 * 3, 128)\n",
    "        self.dense2 = torch.nn.Linear(128, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.max_pooling1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.max_pooling2(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    " \n",
    "model = MyNet()\n",
    "print(model)\n",
    "'''运行结果为：\n",
    "MyNet(\n",
    "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (relu1): ReLU()\n",
    "  (max_pooling1): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
    "  (conv2): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (relu2): ReLU()\n",
    "  (max_pooling2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
    "  (dense1): Linear(in_features=288, out_features=128, bias=True)\n",
    "  (dense2): Linear(in_features=128, out_features=10, bias=True)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 一张图片经过FPN网络的变化过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "\n",
    "# Choose to use a config and initialize the detector\n",
    "config = 'configs/detectors/cascade_rcnn_r50_rfp_1x_coco.py'\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint = 'checkpoints/cascade_rcnn_r50_rfp_1x_coco-bbox-448.pth'\n",
    "# initialize the detector\n",
    "model = init_detector(config, checkpoint, device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the detector to do inference\n",
    "img = 'testImages/test2.jpg'\n",
    "result = inference_detector(model, img)\n",
    "\n",
    "# Let's plot the result\n",
    "show_result_pyplot(model, img, result, score_thr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(l_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mmdet.models.necks.thfpn import THFPN\n",
    "\n",
    "in_channels = [256, 512, 1024, 2048]\n",
    "out_channels = 256\n",
    "\n",
    "#start_level=1,# 开始进行FPN的特征层\n",
    "#add_extra_convs=True,# 是否需要额外的卷积\n",
    "num_outs = 5,#输出的特征数\n",
    "\n",
    "scales = [75, 38, 19, 10]\n",
    "inputs = [torch.rand(1, c, s, s) # 1, channels, scale, scale\n",
    "           for c, s in zip(in_channels, scales)] # 将数据打包成元组\n",
    "self = THFPN(in_channels, 11, len(in_channels)).eval()\n",
    "#out1 = self.__init__()\n",
    "#print(len(in_channels))\n",
    "outputs = self.forward(inputs) # 将数据输入网络进行前向传播\n",
    "#print(len(outputs))\n",
    "for i in range(len(outputs)): #输出数据\n",
    "    print('------------------------')\n",
    "    #print(f'inchannels[{i}]={in_channels[i]}')\n",
    "    print(f'outputs[{i}].shape = {outputs[i].shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pytorch搭建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# 构建输入集\n",
    "x = np.mat('0 0;'\n",
    "           '0 1;'\n",
    "           '1 0;'\n",
    "           '1 1')\n",
    "x = torch.tensor(x).float()\n",
    "y = np.mat('1;'\n",
    "           '0;'\n",
    "           '0;'\n",
    "           '1')\n",
    "y = torch.tensor(y).float()\n",
    "\n",
    "# 搭建网络\n",
    "myNet = nn.Sequential(\n",
    "    nn.Linear(2, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "print(myNet)\n",
    "\n",
    "# 设置优化器\n",
    "optimzer = torch.optim.SGD(myNet.parameters(), lr=0.05)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "for epoch in range(5000):\n",
    "    out = myNet(x)\n",
    "    loss = loss_func(out, y)  # 计算误差\n",
    "    optimzer.zero_grad()  # 清除梯度\n",
    "    loss.backward()\n",
    "    optimzer.step()\n",
    "\n",
    "\n",
    "print(myNet(x).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Backbone ResNet-34 可视化图像提取过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch as t\n",
    "\n",
    "'''\n",
    "    实现子Module:ResidualBlock\n",
    "    ResNet-34结构中都是以2为残差块的\n",
    "    \n",
    "    nn.Conv2d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        bias=True,\n",
    "        padding_mode='zeros',)\n",
    "'''\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, inchannel, outchannel, stride=1, shortcut=None):\n",
    "        super(ResidualBlock, self).__init__()#super().__init__()继承\n",
    "        self.left=nn.Sequential(#self.left重写\n",
    "                nn.Conv2d(inchannel, outchannel, 3, stride, 1 , bias=False),\n",
    "                nn.BatchNorm2d(outchannel),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(outchannel, outchannel, 3,1,1,bias=False),\n",
    "                nn.BatchNorm2d(outchannel))\n",
    "        self.right=shortcut\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.left(x)\n",
    "        residual = x if self.right is None else self.right(x)\n",
    "        out += residual\n",
    "        return F.relu(out)\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    '''\n",
    "    实现主Module:ResNet34\n",
    "    ResNet34包含多个layer，每个layer又包含多个reesidal block\n",
    "    用子module实现residual block，用_make_layer函数实现layer\n",
    "    \n",
    "    nn.MaxPool2d(\n",
    "        kernel_size,\n",
    "        stride=None,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        return_indices=False,\n",
    "        ceil_mode=False,)\n",
    "    '''\n",
    "    def __init__(self, num_classes = 80):\n",
    "        super(ResNet,self).__init__()\n",
    "        #前几层图像转换\n",
    "        self.pre=nn.Sequential(\n",
    "                nn.Conv2d(3 ,64 ,7 ,2 ,3 ,bias = False),#输入三通道rgb，输出64通道,7x7size,步长为2,padding为3\n",
    "                nn.BatchNorm2d(64), # 64通道\n",
    "                nn.ReLU(inplace=True), # relu 激活\n",
    "                nn.MaxPool2d(3, 2, 1) #3x3，步长为2，padding为1\n",
    "                )\n",
    "        #重复的layer，分别有3,4,6,3个residual block\n",
    "        self.layer1 = self._make_layer(64,  64 , 3)\n",
    "        self.layer2 = self._make_layer(64, 128 , 4, stride=2) #默认padding=0\n",
    "        self.layer3 = self._make_layer(128, 256 , 6, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512 , 3, stride=2)\n",
    "        \n",
    "        #分类用的全连接\n",
    "        self.fc=nn.Linear(512, num_classes)#前一个参数是最后神经元的个数最后的num_class是最后的输出类别\n",
    "        \n",
    "    def _make_layer(self, inchannel, outchannel, block_num, stride=1):\n",
    "        '''\n",
    "        构建layer，包含多个residual\n",
    "        '''\n",
    "        shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel))\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(inchannel, outchannel, stride, shortcut))\n",
    "        \n",
    "        for i in range(1, block_num):\n",
    "            layers.append(ResidualBlock(outchannel, outchannel))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        print('图片原始大小',x.size(),)\n",
    "        \n",
    "        x=self.pre(x)\n",
    "        print('conv1:',x.size())\n",
    "        \n",
    "        x=self.layer1(x)\n",
    "        print('conv2:',x.size())\n",
    "        \n",
    "        x=self.layer2(x)\n",
    "        print('conv3:',x.size())\n",
    "            \n",
    "        x=self.layer3(x)\n",
    "        print('conv4:',x.size())\n",
    "        \n",
    "        x=self.layer4(x)\n",
    "        print('conv5:',x.size())\n",
    "        \n",
    "        x=F.avg_pool2d(x,7)\n",
    "        print('池化:',x.size())\n",
    "        \n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.fc(x)\n",
    "        print('全连接:',x.size())\n",
    "        return x\n",
    "\n",
    "model = ResNet()\n",
    "#print(model)\n",
    "input = t.autograd.Variable(t.randn(1,3,224,224))\n",
    "o = model(input)\n",
    "#print(o.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class Person(object):  #class创建类，person 类名，object表示该类从哪里继承下来\n",
    "    pass\n",
    "student = Person()   #创建类的实例化\n",
    "# print(student)\n",
    "# print(Person)            #实例化变量绑定属性\n",
    "student.name = \"Gavin\"   # 为实例变量 student 绑定 name 属性  类似于 赋值 操作\n",
    "student.score = 100    # 为 其绑定 score 属性\n",
    "print(student.name)\n",
    "print(student.score)\n",
    "'''\n",
    "\n",
    "\n",
    "#------为更加简单优雅，使用def __init__(self)方法--------\n",
    "class Person(object):\n",
    "    def __init__(self, name, score):#本身，属性1，属性2\n",
    "        self.name = name\n",
    "        self.score = score\n",
    "        \n",
    "        super(Person, self).__init__()#super()方法既能继承父类方法且能重写方法\n",
    "        self.name1 = name\n",
    "        assert 3 > 2  #通过调用 abort 来终止！程序运行\n",
    "        self.score2 = score #上面条件不成立，终止在上面,所以不会得到打印信息\n",
    "student = Person('Gavin', 100)\n",
    "\n",
    "print(student.name1)\n",
    "print(student.score2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 复现resnet-50 fpn pafpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):#定义类名bottleneck 从nn.Module继承而来\n",
    "    expansion = 4 # resnet-50子模块内通道数的倍数关系\n",
    "\n",
    "    def __init__(self, in_size, size_u, stride=1, is_down=False):#__init__方法，，是否下采样进行通道调整，每一层的第一个卷积\n",
    "        super(Bottleneck, self).__init__()#super().__init__()方法继承Bottleneck 重写父类\n",
    "        #-----------------resnet 子模块结构定义CONV1，BN1，CONV2，BN2...---------------------\n",
    "        self.conv1 = nn.Conv2d(in_size, size_u, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(size_u)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(size_u, size_u, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(size_u)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(size_u, size_u * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(size_u * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = nn.Sequential(#下采样卷积定义\n",
    "            nn.Conv2d(in_size, size_u * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(size_u * self.expansion))\n",
    "        self.stride = stride\n",
    "\n",
    "        self.is_down = is_down\n",
    "\n",
    "    def forward(self, x):#定义子模块内的前向传播函数\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.is_down:#跳连机制 发生在每一层的第一个卷积\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity#跳连与输出融合\n",
    "        out = self.relu(out)#输出前激活\n",
    "\n",
    "        return out #返回最后结果\n",
    "\n",
    "\n",
    "class Resnt50(nn.Module):#定义每一层的层结构\n",
    "    def __init__(self):\n",
    "        super(Resnt50, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.lysize = [64, 128, 256, 512, 1024, 2048]\n",
    "#resnet-50  4层   //3  4  6  3\n",
    "        self.layer1 = nn.Sequential(Bottleneck(self.lysize[0], self.lysize[0], 1, True),\n",
    "                                    Bottleneck(self.lysize[2], self.lysize[0], 1, False),\n",
    "                                    Bottleneck(self.lysize[2], self.lysize[0], 1, False))\n",
    "\n",
    "        self.layer2 = nn.Sequential(Bottleneck(self.lysize[2], self.lysize[1], 2, True),\n",
    "                                    Bottleneck(self.lysize[3], self.lysize[1], 1, False),\n",
    "                                    Bottleneck(self.lysize[3], self.lysize[1], 1, False),\n",
    "                                    Bottleneck(self.lysize[3], self.lysize[1], 1, False))\n",
    "\n",
    "        self.layer3 = nn.Sequential(Bottleneck(self.lysize[3], self.lysize[2], 2, True),\n",
    "                                    Bottleneck(self.lysize[4], self.lysize[2], 1, False),\n",
    "                                    Bottleneck(self.lysize[4], self.lysize[2], 1, False),\n",
    "                                    Bottleneck(self.lysize[4], self.lysize[2], 1, False),\n",
    "                                    Bottleneck(self.lysize[4], self.lysize[2], 1, False),\n",
    "                                    Bottleneck(self.lysize[4], self.lysize[2], 1, False))\n",
    "\n",
    "        self.layer4 = nn.Sequential(Bottleneck(self.lysize[4], self.lysize[3], 2, True),\n",
    "                                    Bottleneck(self.lysize[5], self.lysize[3], 1, False),\n",
    "                                    Bottleneck(self.lysize[5], self.lysize[3], 1, False))\n",
    "\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # self.fc = nn.Linear(self.lysize[5], 3)\n",
    "\n",
    "        for m in self.modules():#初始化conv,bn模块参数\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):#resnet-50整个模块的前向传播\n",
    "        conv1 = self.conv1(x)\n",
    "        bn1 = self.bn1(conv1)\n",
    "        relu = self.relu(bn1)\n",
    "        maxpool = self.maxpool(relu)\n",
    "\n",
    "        layer1 = self.layer1(maxpool)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)\n",
    "        layer4 = self.layer4(layer3)\n",
    "        # x = self.avgpool(layer4)\n",
    "        # x = x.view(x.shape[0], -1)\n",
    "        # x = self.fc(x)\n",
    "        return layer1, layer2, layer3, layer4\n",
    "\n",
    "\n",
    "class FPN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FPN, self).__init__()\n",
    "        self.resnet_feature = Resnt50()# resnet独立的生成每一层的卷积结构\n",
    "        #层与层之间的卷积结构\n",
    "        self.conv1 = nn.Conv2d(in_channels=2048, out_channels=256, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(1024, 256, 1, 1, 0)\n",
    "        self.conv3 = nn.Conv2d(512, 256, 1, 1, 0)\n",
    "        self.conv4 = nn.Conv2d(256, 256, 1, 1, 0)\n",
    "        self.fpn_convs = nn.Conv2d(256, 256, 3, 1, 1)#横向连接 调整通道数\n",
    "\n",
    "    def forward(self, x):#将整个结构的所用组件描述清楚，再将整个组件连接（图像数据的流向）\n",
    "        layer1, layer2, layer3, layer4 = self.resnet_feature(x)  # channel 256 512 1024 2048，输入x，得到每层特征图，\n",
    "\n",
    "        P5_1 = self.conv1(layer4)#最高层的特征图，使用1x1卷积提取    backbone级别输出\n",
    "        P4_1 = self.conv2(layer3)\n",
    "        P3_1 = self.conv3(layer2)\n",
    "        P2_1 = self.conv4(layer1)\n",
    "\n",
    "        size4 = P4_1.shape[2:]#舍去 0  1\n",
    "        size3 = P3_1.shape[2:]\n",
    "        size2 = P2_1.shape[2:]\n",
    "\n",
    "        P5_2 = P5_1\n",
    "        P4_2 = P4_1 + F.interpolate(P5_2, size=size4, mode='nearest')#FPN降采样融合\n",
    "        P3_2 = P3_1 + F.interpolate(P4_2, size=size3, mode='nearest')\n",
    "        P2_2 = P2_1 + F.interpolate(P3_2, size=size2, mode='nearest')\n",
    "\n",
    "        P5_3 = self.fpn_convs(P5_2)     #FPN网络输出\n",
    "        P4_3 = self.fpn_convs(P4_2)\n",
    "        P3_3 = self.fpn_convs(P3_2)\n",
    "        P2_3 = self.fpn_convs(P2_2)\n",
    "\n",
    "        return P5_2, P4_2, P3_2, P2_2\n",
    "        return P2_3, P3_3, P4_3, P5_3\n",
    "\n",
    "\n",
    "class PAFPN(nn.Module):\n",
    "    def __init__(self, class_number=80):\n",
    "        super(PAFPN, self).__init__()\n",
    "        self.fpn = FPN()#  将 FPN 继承下来 \n",
    "        self.convN = nn.Conv2d(256, 256, 3, 2, 1)#末端向上融合卷积模块\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        P2_3, P3_3, P4_3, P5_3 = self.fpn(x)#FPN的输出端\n",
    "\n",
    "        N2 = P2_3  #最下面一级  不涉及特征融合\n",
    "        N2_1 = self.convN(N2)#向 N3 卷积融合\n",
    "        N2_1 = self.relu(N2_1)#激活输出\n",
    "\n",
    "        N3 = N2_1 + P3_3 # 融合\n",
    "\n",
    "        N3_1 = self.convN(N3)\n",
    "        N3_1 = self.relu(N3_1)\n",
    "        N4 = N3_1 + P4_3#融合\n",
    "\n",
    "        N4_1 = self.convN(N4)\n",
    "        N4_1 = self.relu(N4_1)\n",
    "        N5 = N4_1 + P5_3#融合\n",
    "\n",
    "        return N2, N3, N4, N5\n",
    "    \n",
    "\n",
    "class LFP1(nn.Module):\n",
    "    \n",
    "    def __init__(self, class_number=80):\n",
    "        super(LFP1, self).__init__()\n",
    "        self.pafpn = PAFPN()  #将 PAFPN 继承下来 \n",
    "        \n",
    "        self.resnet_feature = Resnt50()# resnet独立的生成每一层的卷积结构\n",
    "        self.fpn_convs = nn.Conv2d(256, 256, 3, 1, 1)#横向连接 调整通道数\n",
    "        self.convN = nn.Conv2d(256, 256, 3, 2, 1)#末端向上融合卷积模块\n",
    "        \n",
    "        self.convF_1 = nn.Conv2d(256, 256, 1, 1, 0)#通过一个1x1的卷积递归\n",
    "        self.convF_2 = nn.Conv2d(256, 512, 1, 1, 0)\n",
    "        self.convF_3 = nn.Conv2d(256, 1024, 1, 1, 0)\n",
    "        self.convF_4 = nn.Conv2d(256, 2048, 1, 1, 0)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=2048, out_channels=256, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(1024, 256, 1, 1, 0)\n",
    "        self.conv3 = nn.Conv2d(512, 256, 1, 1, 0)\n",
    "        self.conv4 = nn.Conv2d(256, 256, 1, 1, 0)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #------------第一次fpn\n",
    "        layer1, layer2, layer3, layer4 = self.resnet_feature(x)  # channel 256 512 1024 2048，输入x，得到每层特征图，\n",
    "\n",
    "        P5_1 = self.conv1(layer4)#最高层的特征图，使用1x1卷积提取    backbone级别输出\n",
    "        P4_1 = self.conv2(layer3)\n",
    "        P3_1 = self.conv3(layer2)\n",
    "        P2_1 = self.conv4(layer1)\n",
    "\n",
    "        size4 = P4_1.shape[2:]#舍去 0  1\n",
    "        size3 = P3_1.shape[2:]\n",
    "        size2 = P2_1.shape[2:]\n",
    "\n",
    "        P5_2 = P5_1\n",
    "        P4_2 = P4_1 + F.interpolate(P5_2, size=size4, mode='nearest')#FPN降采样融合\n",
    "        P3_2 = P3_1 + F.interpolate(P4_2, size=size3, mode='nearest')\n",
    "        P2_2 = P2_1 + F.interpolate(P3_2, size=size2, mode='nearest')\n",
    "\n",
    "        #单层递归\n",
    "        F2_1 = self.convF_1(P2_2)\n",
    "        F2_1 = self.relu(F2_1)\n",
    "        layer1 = F2_1 + layer1\n",
    "        \n",
    "        F3_1 = self.convF_2(P3_2)\n",
    "        F3_1 = self.relu(F3_1)\n",
    "        layer2 = F3_1 + layer2\n",
    "        \n",
    "        F4_1 = self.convF_3(P4_2)\n",
    "        F4_1 = self.relu(F4_1)  \n",
    "        layer3 = F4_1 + layer3\n",
    "        \n",
    "        F5_1 = self.convF_4(P5_2)\n",
    "        F5_1 = self.relu(F5_1)\n",
    "        layer4 = F5_1 + layer4\n",
    "        \n",
    "        #-------------------第二次FPN\n",
    "        P5_1 = self.conv1(layer4)#最高层的特征图，使用1x1卷积提取    backbone级别输出\n",
    "        P4_1 = self.conv2(layer3)\n",
    "        P3_1 = self.conv3(layer2)\n",
    "        P2_1 = self.conv4(layer1)\n",
    "\n",
    "        size4 = P4_1.shape[2:]#舍去 0  1\n",
    "        size3 = P3_1.shape[2:]\n",
    "        size2 = P2_1.shape[2:]\n",
    "\n",
    "        P5_2 = P5_1\n",
    "        P4_2 = P4_1 + F.interpolate(P5_2, size=size4, mode='nearest')#FPN降采样融合\n",
    "        P3_2 = P3_1 + F.interpolate(P4_2, size=size3, mode='nearest')\n",
    "        P2_2 = P2_1 + F.interpolate(P3_2, size=size2, mode='nearest')\n",
    "        \n",
    "        P5_3 = self.fpn_convs(P5_2)     #FPN网络输出\n",
    "        P4_3 = self.fpn_convs(P4_2)\n",
    "        P3_3 = self.fpn_convs(P3_2)\n",
    "        P2_3 = self.fpn_convs(P2_2)\n",
    "        \n",
    "        #------pafpn------\n",
    "        N2 = P2_3  #最下面一级  不涉及特征融合\n",
    "        N2_1 = self.convN(N2)#向 N3 卷积融合\n",
    "        N2_1 = self.relu(N2_1)#激活输出\n",
    "\n",
    "        N3 = N2_1 + P3_3 # 融合\n",
    "\n",
    "        N3_1 = self.convN(N3)\n",
    "        N3_1 = self.relu(N3_1)\n",
    "        N4 = N3_1 + P4_3#融合\n",
    "\n",
    "        N4_1 = self.convN(N4)\n",
    "        N4_1 = self.relu(N4_1)\n",
    "        N5 = N4_1 + P5_3#融合\n",
    "\n",
    "        return N2, N3, N4, N5\n",
    "\n",
    "    \n",
    "class LFP(nn.Module):\n",
    "    def __init__(self, class_number=80):\n",
    "        super(LFP, self).__init__()\n",
    "        self.pafpn = PAFPN()\n",
    "        #==================FPN=======================\n",
    "        self.resnet_feature = Resnt50()# resnet独立的生成每一层的卷积结构\n",
    "        #层与层之间的卷积结构\n",
    "        self.conv1 = nn.Conv2d(in_channels=2048, out_channels=256, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(1024, 256, 1, 1, 0)\n",
    "        self.conv3 = nn.Conv2d(512, 256, 1, 1, 0)\n",
    "        self.conv4 = nn.Conv2d(256, 256, 1, 1, 0)\n",
    "        self.fpn_convs = nn.Conv2d(256, 256, 3, 1, 1)#横向连接 调整通道数\n",
    "        self.convN = nn.Conv2d(256, 256, 3, 2, 1)#末端向上融合卷积模块\n",
    "        self.convL = nn.Conv2d(256, 256, 1, 1, 0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):#将整个结构的所用组件描述清楚，再将整个组件连接（图像数据的流向）\n",
    "        #————————>FPN————————>PAFPN输出\n",
    "        layer1, layer2, layer3, layer4 = self.resnet_feature(x)  # channel 256 512 1024 2048，输入x，得到每层特征图，\n",
    "\n",
    "        P5_1 = self.conv1(layer4)#最高层的特征图，使用1x1卷积提取    backbone级别输出\n",
    "        P4_1 = self.conv2(layer3)\n",
    "        P3_1 = self.conv3(layer2)\n",
    "        P2_1 = self.conv4(layer1)\n",
    "        print(P2_1.shape)\n",
    "\n",
    "        size4 = P4_1.shape[2:]#舍去 0  1\n",
    "        size3 = P3_1.shape[2:]\n",
    "        size2 = P2_1.shape[2:]\n",
    "\n",
    "        P5_2 = P5_1\n",
    "        P4_2 = P4_1 + F.interpolate(P5_2, size=size4, mode='nearest')#FPN降采样融合\n",
    "        P3_2 = P3_1 + F.interpolate(P4_2, size=size3, mode='nearest')\n",
    "        P2_2 = P2_1 + F.interpolate(P3_2, size=size2, mode='nearest')\n",
    "\n",
    "        P5_3 = self.fpn_convs(P5_2)     #FPN网络输出\n",
    "        P4_3 = self.fpn_convs(P4_2)\n",
    "        P3_3 = self.fpn_convs(P3_2)\n",
    "        P2_3 = self.fpn_convs(P2_2)\n",
    "        \n",
    "        #==================PAFPN=========================\n",
    "        N2 = P2_3  #最下面一级  不涉及特征融合\n",
    "        N2_1 = self.convN(N2)#向 N3 卷积融合\n",
    "        N2_1 = self.relu(N2_1)#激活输出\n",
    "\n",
    "        N3 = N2_1 + P3_3 # 融合\n",
    "\n",
    "        N3_1 = self.convN(N3)\n",
    "        N3_1 = self.relu(N3_1)\n",
    "        N4 = N3_1 + P4_3#融合\n",
    "\n",
    "        N4_1 = self.convN(N4)\n",
    "        N4_1 = self.relu(N4_1)\n",
    "        N5 = N4_1 + P5_3#融合\n",
    "        \n",
    " \n",
    "    \n",
    "        #===================LFP=====================\n",
    "        N5_1 = self.convL(N5)\n",
    "        N5_1 = self.relu(N5_1)\n",
    "        print(\"打印N5_1：\",N5.shape)\n",
    "        print(\"打印P5_1：\",P5_1.shape)\n",
    " \n",
    "        #-----LFP循环 更新FPN参数------------\n",
    "        P5_2 = N5_1 + P5_1 #改进点，引入反馈\n",
    "        P4_2 = P4_1 + F.interpolate(P5_2, size=size4, mode='nearest')#FPN降采样融合\n",
    "        P3_2 = P3_1 + F.interpolate(P4_2, size=size3, mode='nearest')\n",
    "        P2_2 = P2_1 + F.interpolate(P3_2, size=size2, mode='nearest')\n",
    "        \n",
    "        P5_3 = self.fpn_convs(P5_2)     #FPN网络输出\n",
    "        P4_3 = self.fpn_convs(P4_2)\n",
    "        P3_3 = self.fpn_convs(P3_2)\n",
    "        P2_3 = self.fpn_convs(P2_2)\n",
    "        \n",
    "        N2 = P2_3  #最下面一级  不涉及特征融合\n",
    "        N2_1 = self.convN(N2)#向 N3 卷积融合\n",
    "        N2_1 = self.relu(N2_1)#激活输出\n",
    "\n",
    "        N3 = N2_1 + P3_3 # 融合\n",
    "\n",
    "        N3_1 = self.convN(N3)\n",
    "        N3_1 = self.relu(N3_1)\n",
    "        N4 = N3_1 + P4_3#融合\n",
    "\n",
    "        N4_1 = self.convN(N4)\n",
    "        N4_1 = self.relu(N4_1)\n",
    "        N5 = N4_1 + P5_3#融合\n",
    "        \n",
    "        return N2, N3, N4, N5\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    from torchsummary import summary\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LFP().to(device)\n",
    "\n",
    "    summary(model, (3, 600, 600))#输入数据 3x600x512\n",
    "    '''\n",
    "    for parameters in model.parameters():#打印出参数矩阵及值\n",
    "        print(parameters)\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    for name, parameters in model.named_parameters():#打印出每一层的参数的大小\n",
    "        print(name, ':', parameters.size())\n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import torch\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "\n",
    "from mmdet.models.necks import FPN, ChannelMapper\n",
    "\n",
    "\n",
    "def test_fpn():\n",
    "    \"\"\"Tests fpn. 每一层对应的特征图大小以及C234依然混淆    \"\"\"\n",
    "    s = 600\n",
    "    in_channels = [256, 512, 1024, 2048]\n",
    "    feat_sizes = [s // 2**i for i in range(4)]  # [600, 300, 150, 75]\n",
    "    #print(feat_sizes)\n",
    "    out_channels = 256\n",
    "    # `num_outs` is not equal to len(in_channels) - start_level\n",
    "    with pytest.raises(AssertionError):\n",
    "        FPN(in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            start_level=1,\n",
    "            num_outs=2)\n",
    "\n",
    "    # `end_level` is larger than len(in_channels) - 1\n",
    "    with pytest.raises(AssertionError):\n",
    "        FPN(in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            start_level=1,\n",
    "            end_level=4,\n",
    "            num_outs=2)\n",
    "\n",
    "    # `num_outs` is not equal to end_level - start_level\n",
    "    with pytest.raises(AssertionError):\n",
    "        FPN(in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            start_level=1,\n",
    "            end_level=3,\n",
    "            num_outs=1)\n",
    "\n",
    "    # Invalid `add_extra_convs` option\n",
    "    with pytest.raises(AssertionError):\n",
    "        FPN(in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            start_level=1,\n",
    "            add_extra_convs='on_xxx',\n",
    "            num_outs=5)\n",
    "\n",
    "    fpn_model = FPN(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        start_level=1,\n",
    "        add_extra_convs=True,#添加了额外的卷积操作时，如 RetinaNet\n",
    "        num_outs=5)\n",
    "    #print(fpn_model)#输出卷积信息，lateral_conv和fpn_conv信息\n",
    "\n",
    "    # FPN expects a multiple levels of features per image\n",
    "    feats = [\n",
    "        torch.rand(1, in_channels[i], feat_sizes[i], feat_sizes[i])\n",
    "        for i in range(len(in_channels))\n",
    "    ]\n",
    "    outs = fpn_model(feats)\n",
    "    assert fpn_model.add_extra_convs == 'on_input'\n",
    "    assert len(outs) == fpn_model.num_outs\n",
    "    for i in range(fpn_model.num_outs):\n",
    "        outs[i].shape[1] == out_channels\n",
    "        outs[i].shape[2] == outs[i].shape[3] == s // (2**i)\n",
    "\n",
    "    # Tests for fpn with no extra convs (pooling is used instead)\n",
    "    fpn_model = FPN(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        start_level=1,\n",
    "        add_extra_convs=False,#没有添加额外的卷积操作，如 Fasetr R-CNN\n",
    "        num_outs=5)\n",
    "    outs = fpn_model(feats)\n",
    "    #print(outs)\n",
    "    \n",
    "    assert len(outs) == fpn_model.num_outs\n",
    "    assert not fpn_model.add_extra_convs\n",
    "    for i in range(fpn_model.num_outs):\n",
    "        outs[i].shape[1] == out_channels\n",
    "        outs[i].shape[2] == outs[i].shape[3] == s // (2**i)\n",
    "\n",
    "    # Tests for fpn with lateral bns\n",
    "    fpn_model = FPN(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        start_level=1,\n",
    "        add_extra_convs=True,\n",
    "        no_norm_on_lateral=False,\n",
    "        norm_cfg=dict(type='BN', requires_grad=True),\n",
    "        num_outs=5)\n",
    "    outs = fpn_model(feats)\n",
    "    assert len(outs) == fpn_model.num_outs\n",
    "    assert fpn_model.add_extra_convs == 'on_input'\n",
    "    for i in range(fpn_model.num_outs):\n",
    "        outs[i].shape[1] == out_channels\n",
    "        outs[i].shape[2] == outs[i].shape[3] == s // (2**i)\n",
    "    bn_exist = False\n",
    "    for m in fpn_model.modules():\n",
    "        if isinstance(m, _BatchNorm):\n",
    "            bn_exist = True\n",
    "    assert bn_exist\n",
    "\n",
    "    # Bilinear upsample\n",
    "    fpn_model = FPN(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        start_level=1,\n",
    "        add_extra_convs=True,\n",
    "        upsample_cfg=dict(mode='bilinear', align_corners=True),\n",
    "        num_outs=5)\n",
    "    fpn_model(feats)\n",
    "    outs = fpn_model(feats)\n",
    "    assert len(outs) == fpn_model.num_outs\n",
    "    assert fpn_model.add_extra_convs == 'on_input'\n",
    "    for i in range(fpn_model.num_outs):\n",
    "        outs[i].shape[1] == out_channels\n",
    "        outs[i].shape[2] == outs[i].shape[3] == s // (2**i)\n",
    "\n",
    "    # Scale factor instead of fixed upsample size upsample\n",
    "    fpn_model = FPN(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        start_level=1,\n",
    "        add_extra_convs=True,\n",
    "        upsample_cfg=dict(scale_factor=2),\n",
    "        num_outs=5)\n",
    "    outs = fpn_model(feats)\n",
    "    assert len(outs) == fpn_model.num_outs\n",
    "    for i in range(fpn_model.num_outs):\n",
    "        outs[i].shape[1] == out_channels\n",
    "        outs[i].shape[2] == outs[i].shape[3] == s // (2**i)\n",
    "\n",
    "    # Extra convs source is 'inputs'\n",
    "    fpn_model = FPN(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        add_extra_convs='on_input',\n",
    "        start_level=1,\n",
    "        num_outs=5)\n",
    "    assert fpn_model.add_extra_convs == 'on_input'\n",
    "    outs = fpn_model(feats)\n",
    "    assert len(outs) == fpn_model.num_outs\n",
    "    for i in range(fpn_model.num_outs):\n",
    "        outs[i].shape[1] == out_channels\n",
    "        outs[i].shape[2] == outs[i].shape[3] == s // (2**i)\n",
    "\n",
    "    # Extra convs source is 'laterals'\n",
    "    fpn_model = FPN(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        add_extra_convs='on_lateral',\n",
    "        start_level=1,\n",
    "        num_outs=5)\n",
    "    assert fpn_model.add_extra_convs == 'on_lateral'\n",
    "    outs = fpn_model(feats)\n",
    "    assert len(outs) == fpn_model.num_outs\n",
    "    for i in range(fpn_model.num_outs):\n",
    "        outs[i].shape[1] == out_channels\n",
    "        outs[i].shape[2] == outs[i].shape[3] == s // (2**i)\n",
    "\n",
    "    # Extra convs source is 'outputs'\n",
    "    fpn_model = FPN(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        add_extra_convs='on_output',\n",
    "        start_level=1,\n",
    "        num_outs=5)\n",
    "    assert fpn_model.add_extra_convs == 'on_output'\n",
    "    outs = fpn_model(feats)\n",
    "    assert len(outs) == fpn_model.num_outs\n",
    "    for i in range(fpn_model.num_outs):\n",
    "        outs[i].shape[1] == out_channels\n",
    "        outs[i].shape[2] == outs[i].shape[3] == s // (2**i)\n",
    "\n",
    "    # extra_convs_on_inputs=False is equal to extra convs source is 'on_output'\n",
    "    fpn_model = FPN(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        add_extra_convs=True,\n",
    "        extra_convs_on_inputs=False,\n",
    "        start_level=1,\n",
    "        num_outs=5,\n",
    "    )\n",
    "    assert fpn_model.add_extra_convs == 'on_output'\n",
    "    outs = fpn_model(feats)\n",
    "    assert len(outs) == fpn_model.num_outs\n",
    "    for i in range(fpn_model.num_outs):\n",
    "        outs[i].shape[1] == out_channels\n",
    "        outs[i].shape[2] == outs[i].shape[3] == s // (2**i)\n",
    "\n",
    "    # extra_convs_on_inputs=True is equal to extra convs source is 'on_input'\n",
    "    fpn_model = FPN(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        add_extra_convs=True,\n",
    "        extra_convs_on_inputs=True,\n",
    "        start_level=1,\n",
    "        num_outs=5,\n",
    "    )\n",
    "    assert fpn_model.add_extra_convs == 'on_input'\n",
    "    outs = fpn_model(feats)\n",
    "    assert len(outs) == fpn_model.num_outs\n",
    "    for i in range(fpn_model.num_outs):\n",
    "        outs[i].shape[1] == out_channels\n",
    "        outs[i].shape[2] == outs[i].shape[3] == s // (2**i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import torch\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "from mmdet.models.necks import PAFPN,ChannelMapper\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    s = 600\n",
    "    in_channels = [256, 512, 1024, 2048]\n",
    "    feat_sizes = [s // 2**i for i in range(4)]  # [600, 300, 150, 75]\n",
    "#    print(feat_sizes)\n",
    "    out_channels = 256\n",
    "    fpn_model = PAFPN(\n",
    "        in_channels = in_channels,\n",
    "        out_channels = out_channels,\n",
    "        start_level = 0,\n",
    "        add_extra_convs = False,#C2---C5  用mask-rcnn\n",
    "        num_outs = 5)\n",
    "    '''\n",
    "        feats = [\n",
    "        torch.rand(1, in_channels[i], feat_sizes[i], feat_sizes[i])\n",
    "        for i in range(len(in_channels))\n",
    "            ]\n",
    "    '''\n",
    "\n",
    "\n",
    "    print(fpn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.runner import auto_fp16\n",
    "\n",
    "from mmdet.models.builder import NECKS\n",
    "from mmdet.models.necks.fpn import FPN\n",
    "\n",
    "\n",
    "#@NECKS.register_module()\n",
    "class LFP(FPN):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_outs,\n",
    "                 start_level=0,\n",
    "                 end_level=-1,\n",
    "                 add_extra_convs=False,\n",
    "                 extra_convs_on_inputs=True,\n",
    "                 relu_before_extra_convs=False,\n",
    "                 no_norm_on_lateral=False,\n",
    "                 conv_cfg=None,\n",
    "                 norm_cfg=None,\n",
    "                 act_cfg=None):\n",
    "        super(LFP,\n",
    "              self).__init__(in_channels, out_channels, num_outs, start_level,\n",
    "                             end_level, add_extra_convs, extra_convs_on_inputs,\n",
    "                             relu_before_extra_convs, no_norm_on_lateral,\n",
    "                             conv_cfg, norm_cfg, act_cfg)\n",
    "\n",
    "        # add extra bottom up pathway（至下而上的卷积融合）\n",
    "#        self.recursive_convs = nn.ModuleList()#递归卷积\n",
    "        self.downsample_convs = nn.ModuleList()#下采样卷积，图中的后半部分\n",
    "        self.pafpn_convs = nn.ModuleList()#pafpn卷积\n",
    "\n",
    "        self.convL = nn.Conv2d(256, 256, 1, 1, 0)\n",
    "\n",
    "#----------------------------------------------\n",
    "        for i in range(self.start_level + 1, self.backbone_end_level):\n",
    "\n",
    "            d_conv = ConvModule(\n",
    "                out_channels,                         \n",
    "                out_channels,\n",
    "                3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                conv_cfg=conv_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=act_cfg,\n",
    "                inplace=False)\n",
    "\n",
    "            pafpn_conv = ConvModule(       #输出前卷积\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                3,\n",
    "                padding=1,\n",
    "                conv_cfg=conv_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=act_cfg,\n",
    "                inplace=False)\n",
    "\n",
    "            self.downsample_convs.append(d_conv)\n",
    "            self.pafpn_convs.append(pafpn_conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mmcv.cnn import ConvModule\n",
    "from mmcv.runner import auto_fp16\n",
    "\n",
    "from mmdet.models.builder import NECKS\n",
    "from mmdet.models.necks.fpn import FPN\n",
    "\n",
    "\n",
    "#@NECKS.register_module()\n",
    "class LFP(FPN):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_outs,\n",
    "                 start_level=0,\n",
    "                 end_level=-1,\n",
    "                 add_extra_convs=False,\n",
    "                 extra_convs_on_inputs=True,\n",
    "                 relu_before_extra_convs=False,\n",
    "                 no_norm_on_lateral=False,\n",
    "                 conv_cfg=None,\n",
    "                 norm_cfg=None,\n",
    "                 act_cfg=None):\n",
    "        super(LFP,\n",
    "              self).__init__(in_channels, out_channels, num_outs, start_level,\n",
    "                             end_level, add_extra_convs, extra_convs_on_inputs,\n",
    "                             relu_before_extra_convs, no_norm_on_lateral,\n",
    "                             conv_cfg, norm_cfg, act_cfg)\n",
    "\n",
    "        # add extra bottom up pathway（至下而上的卷积融合）\n",
    "#        self.recursive_convs = nn.ModuleList()#递归卷积\n",
    "        self.downsample_convs = nn.ModuleList()#下采样卷积，图中的后半部分\n",
    "        self.pafpn_convs = nn.ModuleList()#pafpn卷积\n",
    "\n",
    "        self.convL = nn.Conv2d(256, 256, 1, 1, 0)\n",
    "#----------------------------------------------\n",
    "        for i in range(self.start_level + 1, self.backbone_end_level):\n",
    "\n",
    "            d_conv = ConvModule(         #降采样卷积 k=3,p=1,s=2时的卷积输入输出大小/2\n",
    "                out_channels,                         \n",
    "                out_channels,\n",
    "                3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                conv_cfg=conv_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=act_cfg,\n",
    "                inplace=False)\n",
    "\n",
    "            pafpn_conv = ConvModule(       #输出前卷积 k=3,p=1,s=1时的卷积输入输出大小不变\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                3,\n",
    "                padding=1,\n",
    "                conv_cfg=conv_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=act_cfg,\n",
    "                inplace=False)\n",
    "\n",
    "            self.downsample_convs.append(d_conv)\n",
    "            self.pafpn_convs.append(pafpn_conv)\n",
    "\n",
    "\n",
    "    @auto_fp16()\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward function.\"\"\"\n",
    "        assert len(inputs) == len(self.in_channels)\n",
    "        # build laterals    调整C=256通道后\n",
    "        laterals = [\n",
    "            lateral_conv(inputs[i + self.start_level])\n",
    "            for i, lateral_conv in enumerate(self.lateral_convs)\n",
    "        ]\n",
    "        pre_laterals = [\n",
    "            lateral_conv(inputs[i + self.start_level])\n",
    "            for i, lateral_conv in enumerate(self.lateral_convs)\n",
    "        ]\n",
    "\n",
    "#C\n",
    "        # build top-down path\n",
    "        used_backbone_levels = len(laterals) # used_backbone_levels = 4\n",
    "#        print(\"used_backbone_levels：\",len(laterals))\n",
    "#M\n",
    "  #融合前后存在覆盖问题\n",
    "        for i in range(used_backbone_levels - 1, 0, -1):# 倒序   3，2，1(倒序输出，不包括0)\n",
    "            prev_shape = laterals[i - 1].shape[2:] #上采样过程中间的一个size参数\n",
    "            #laterals[i]上一层的下采样与backbone中laterals卷积输出的lateral[i-1]进行相加融合，融合为lateral[i-1]\n",
    "            laterals[i - 1] = laterals[i - 1] + F.interpolate(laterals[i],\n",
    "                size=prev_shape, mode='nearest')#最近领域插值\n",
    "            #保留前次循环的特征图\n",
    "            pre_laterals[i - 1] = laterals[i - 1]#初始化\n",
    "        #print(f'里面laterals[{i}]={laterals[i-1].shape}')\n",
    "            #    print(f'outputs[{i}].shape = {outputs[i].shape}')  带编号i输出\n",
    "        # build outputs\n",
    "        # part 1: from original levels\n",
    "        inter_outs = [\n",
    "            self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels)\n",
    "        ]   #第一级输出，后面融合的使用append()方法\n",
    "        #定义pre\n",
    "        pre_inter_outs = inter_outs\n",
    "        # part 2: add bottom-up path  至下而上路径融合输出\n",
    "        for i in range(0, used_backbone_levels - 1):\n",
    "            inter_outs[i + 1] = inter_outs[i + 1] + self.downsample_convs[i](inter_outs[i])\n",
    "\n",
    "            pre_inter_outs[i + 1] = inter_outs[i + 1]#初始化\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#此时的输出是：在RetinaNet中C3，C4，C5在backbone输出，FPN融合至下而上最后输出\n",
    "#========================Improved===============\n",
    "\n",
    "        \n",
    "        loop = 2\n",
    "        for i in range(loop):#概括整个循环\n",
    "            laterals[used_backbone_levels - 1] = laterals[used_backbone_levels - 1] + self.convL(inter_outs[used_backbone_levels - 1])\n",
    "#        print(\"laterals[used_backbone_levels - 1].shape:\",laterals[used_backbone_levels - 1].shape)\n",
    "#C\n",
    "            laterals = [\n",
    "            lateral_conv(inputs[i + self.start_level])\n",
    "            for i, lateral_conv in enumerate(self.lateral_convs)\n",
    "            ]       \n",
    "\n",
    "\n",
    "#C ---> LFP function, here,forward again        \n",
    "            laterals[used_backbone_levels - 1] = laterals[used_backbone_levels - 1] + self.convL(inter_outs[used_backbone_levels - 1])\n",
    "            pre_laterals[used_backbone_levels - 1] = laterals[used_backbone_levels - 1]#最高层保留\n",
    "        # build top-down path\n",
    "            used_backbone_levels = len(laterals) # used_backbone_levels = 4\n",
    "#M\n",
    "            for i in range(used_backbone_levels - 1, 0, -1):# 倒序   3，2，1\n",
    "                prev_shape = laterals[i - 1].shape[2:]\n",
    "                laterals[i - 1] = laterals[i - 1] + F.interpolate(\n",
    "                    laterals[i], size=prev_shape, mode='nearest') + pre_laterals[i - 1] + F.interpolate(inter_outs[i],\n",
    "                size=prev_shape, mode='nearest')   #设置空洞卷积\n",
    "                pre_laterals[i - 1] = laterals[i - 1]\n",
    "     \n",
    "            #laterals[2],   laterals[1],   laterals[0] 对应 M4，M3，M2\n",
    "        # build outputs\n",
    "        # part 1: from original levels\n",
    "            inter_outs = [  #for i range(3)  输出0,1，2不包括3\n",
    "                    self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels)\n",
    "                ]   #第一级输出，后面融合的使用append()方法\n",
    "#P\n",
    "        # part 2: add bottom-up path  至下而上路径融合输出\n",
    "            for i in range(0, used_backbone_levels - 1): # 0,1,2 不包括3\n",
    "                inter_outs[i + 1] = inter_outs[i + 1] + self.downsample_convs[i](inter_outs[i]) + pre_inter_outs[i + 1]\n",
    "                pre_inter_outs[i + 1] = inter_outs[i + 1]\n",
    "\n",
    " #=================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "        outs = []\n",
    "        #inter_outs[0]不涉及融合，将inter_outs[0]粘贴进入元组\n",
    "        outs.append(inter_outs[0])#融合第一级输出\n",
    "        outs.extend([\n",
    "            self.pafpn_convs[i - 1](inter_outs[i])\n",
    "            for i in range(1, used_backbone_levels)#1，2，3\n",
    "        ])\n",
    "\n",
    "        # part 3: add extra levels   推理P6，P7层的输出\n",
    "        if self.num_outs > len(outs):#如果设定的输出 大于 backbone的输出\n",
    "            # use max pool to get more levels on top of outputs\n",
    "            # (e.g., Faster R-CNN, Mask R-CNN)\n",
    "            if not self.add_extra_convs:#如果没有额外添加其它层，C2-C5，faser，mask\n",
    "                for i in range(self.num_outs - used_backbone_levels):\n",
    "                    outs.append(F.max_pool2d(outs[-1], 1, stride=2))\n",
    "\n",
    "            # add conv layers on top of original feature maps (RetinaNet)\n",
    "            else:\n",
    "                if self.extra_convs_on_inputs:\n",
    "                    orig = inputs[self.backbone_end_level - 1]\n",
    "                    outs.append(self.fpn_convs[used_backbone_levels](orig))\n",
    "                else:\n",
    "                    outs.append(self.fpn_convs[used_backbone_levels](outs[-1]))\n",
    "                for i in range(used_backbone_levels + 1, self.num_outs):\n",
    "                    if self.relu_before_extra_convs:\n",
    "                        outs.append(self.fpn_convs[i](F.relu(outs[-1])))\n",
    "                    else:\n",
    "                        outs.append(self.fpn_convs[i](outs[-1]))\n",
    "        return tuple(outs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    s = 300\n",
    "    in_channels = [256, 512, 1024, 2048]\n",
    "    feat_sizes = [s // 2**i for i in range(4)]  # [600, 300, 150, 75]\n",
    "#    print(feat_sizes)\n",
    "    out_channels = 256\n",
    "    num_outs = 5\n",
    "    fpn_model = LFP(\n",
    "        in_channels = in_channels,\n",
    "        out_channels = out_channels,\n",
    "        start_level = 0,\n",
    "        add_extra_convs = False,#C2---C5  用mask-rcnn\n",
    "        num_outs = num_outs )\n",
    "    \n",
    "    inputs = [\n",
    "        torch.rand(1, in_channels[i], feat_sizes[i], feat_sizes[i])\n",
    "        for i in range(len(in_channels))]\n",
    "      \n",
    "    #print(len(inputs))\n",
    "    LFP.forward(fpn_model, inputs)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    #summary(fpn_model, (3, 600, 600))#输入数据 3x600x512\n",
    "    #print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/htang/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
      "  'The old API of register_module(module, force=False) '\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Carafe is not implemented on CPU",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-907515d00e02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m#print(len(inputs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0mLFP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;31m#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-907515d00e02>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaterals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0mupsample_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaterals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mupsample_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaterals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/ops/carafe.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_normalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_reassemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/ops/carafe.py\u001b[0m in \u001b[0;36mfeature_reassemble\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeature_reassemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcarafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/ops/carafe.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, features, masks, kernel_size, group_size, scale_factor)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mgroup_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             scale_factor=scale_factor)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Carafe is not implemented on CPU"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mmcv.cnn import ConvModule\n",
    "from mmcv.runner import auto_fp16\n",
    "\n",
    "from mmdet.models.builder import NECKS\n",
    "from mmdet.models.necks.fpn import FPN\n",
    "\n",
    "\n",
    "from mmcv.cnn import ConvModule, build_upsample_layer, xavier_init\n",
    "from mmcv.ops.carafe import CARAFEPack\n",
    "\n",
    "\n",
    "\n",
    "#@NECKS.register_module()\n",
    "class LFP(nn.Module):\n",
    "    \"\"\"FPN_CARAFE is a more flexible implementation of FPN. It allows more\n",
    "    choice for upsample methods during the top-down pathway.\n",
    "\n",
    "    It can reproduce the preformance of ICCV 2019 paper\n",
    "    CARAFE: Content-Aware ReAssembly of FEatures\n",
    "    Please refer to https://arxiv.org/abs/1905.02188 for more details.\n",
    "\n",
    "    Args:\n",
    "        in_channels (list[int]): Number of channels for each input feature map.\n",
    "        out_channels (int): Output channels of feature pyramids.\n",
    "        num_outs (int): Number of output stages.\n",
    "        start_level (int): Start level of feature pyramids.\n",
    "            (Default: 0)\n",
    "        end_level (int): End level of feature pyramids.\n",
    "            (Default: -1 indicates the last level).\n",
    "        norm_cfg (dict): Dictionary to construct and config norm layer.\n",
    "        activate (str): Type of activation function in ConvModule\n",
    "            (Default: None indicates w/o activation).\n",
    "        order (dict): Order of components in ConvModule.\n",
    "        upsample (str): Type of upsample layer.\n",
    "        upsample_cfg (dict): Dictionary to construct and config upsample layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_outs,\n",
    "                 start_level=0,\n",
    "                 end_level=-1,\n",
    "                 norm_cfg=None,\n",
    "                 act_cfg=None,\n",
    "                 order=('conv', 'norm', 'act'),\n",
    "                 upsample_cfg=dict(\n",
    "                     type='carafe',\n",
    "                     up_kernel=5,\n",
    "                     up_group=1,\n",
    "                     encoder_kernel=3,\n",
    "                     encoder_dilation=1)):\n",
    "        super(LFP, self).__init__()\n",
    "        assert isinstance(in_channels, list)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_ins = len(in_channels)\n",
    "        self.num_outs = num_outs\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        self.with_bias = norm_cfg is None\n",
    "        self.upsample_cfg = upsample_cfg.copy()\n",
    "        self.upsample = self.upsample_cfg.get('type')\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "        self.order = order\n",
    "        assert order in [('conv', 'norm', 'act'), ('act', 'conv', 'norm')]\n",
    "\n",
    "        assert self.upsample in [\n",
    "            'nearest', 'bilinear', 'deconv', 'pixel_shuffle', 'carafe', None\n",
    "        ]\n",
    "        if self.upsample in ['deconv', 'pixel_shuffle']:\n",
    "            assert hasattr(\n",
    "                self.upsample_cfg,\n",
    "                'upsample_kernel') and self.upsample_cfg.upsample_kernel > 0\n",
    "            self.upsample_kernel = self.upsample_cfg.pop('upsample_kernel')\n",
    "\n",
    "        if end_level == -1:\n",
    "            self.backbone_end_level = self.num_ins\n",
    "            assert num_outs >= self.num_ins - start_level\n",
    "        else:\n",
    "            # if end_level < inputs, no extra level is allowed\n",
    "            self.backbone_end_level = end_level\n",
    "            assert end_level <= len(in_channels)\n",
    "            assert num_outs == end_level - start_level\n",
    "        self.start_level = start_level\n",
    "        self.end_level = end_level\n",
    "\n",
    "        self.lateral_convs = nn.ModuleList()\n",
    "        self.fpn_convs = nn.ModuleList()\n",
    "        self.upsample_modules = nn.ModuleList()\n",
    "\n",
    "#add=========================================\n",
    "        # add extra bottom up pathway（至下而上的卷积融合）\n",
    "        self.downsample_convs = nn.ModuleList()#下采样卷积，图中的后半部分\n",
    "        self.pafpn_convs = nn.ModuleList()#至下而上pafpn卷积\n",
    "        for i in range(self.start_level + 1, self.backbone_end_level):\n",
    "            d_conv = ConvModule(\n",
    "                out_channels,                         \n",
    "                out_channels,\n",
    "                3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                bias=self.with_bias,\n",
    "                act_cfg=act_cfg,\n",
    "                inplace=False,\n",
    "                order=self.order)\n",
    "\n",
    "            pafpn_conv = ConvModule(      #输出前卷积\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                3,\n",
    "                padding=1,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                bias=self.with_bias,\n",
    "                act_cfg=act_cfg,\n",
    "                inplace=False,\n",
    "                order=self.order)\n",
    "            self.downsample_convs.append(d_conv)\n",
    "            self.pafpn_convs.append(pafpn_conv)\n",
    "#=========================================\n",
    "\n",
    "        for i in range(self.start_level, self.backbone_end_level):\n",
    "            l_conv = ConvModule(\n",
    "                in_channels[i],\n",
    "                out_channels,\n",
    "                1,\n",
    "                norm_cfg=norm_cfg,\n",
    "                bias=self.with_bias,\n",
    "                act_cfg=act_cfg,\n",
    "                inplace=False,\n",
    "                order=self.order)\n",
    "            fpn_conv = ConvModule(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                3,\n",
    "                padding=1,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                bias=self.with_bias,\n",
    "                act_cfg=act_cfg,\n",
    "                inplace=False,\n",
    "                order=self.order)\n",
    "            if i != self.backbone_end_level - 1:\n",
    "                upsample_cfg_ = self.upsample_cfg.copy()\n",
    "                if self.upsample == 'deconv':\n",
    "                    upsample_cfg_.update(\n",
    "                        in_channels=out_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=self.upsample_kernel,\n",
    "                        stride=2,\n",
    "                        padding=(self.upsample_kernel - 1) // 2,\n",
    "                        output_padding=(self.upsample_kernel - 1) // 2)\n",
    "                elif self.upsample == 'pixel_shuffle':\n",
    "                    upsample_cfg_.update(\n",
    "                        in_channels=out_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        scale_factor=2,\n",
    "                        upsample_kernel=self.upsample_kernel)\n",
    "                elif self.upsample == 'carafe':\n",
    "                    upsample_cfg_.update(channels=out_channels, scale_factor=2)\n",
    "                else:\n",
    "                    # suppress warnings\n",
    "                    align_corners = (None\n",
    "                                     if self.upsample == 'nearest' else False)\n",
    "                    upsample_cfg_.update(\n",
    "                        scale_factor=2,\n",
    "                        mode=self.upsample,\n",
    "                        align_corners=align_corners)\n",
    "                upsample_module = build_upsample_layer(upsample_cfg_)\n",
    "                self.upsample_modules.append(upsample_module)\n",
    "            self.lateral_convs.append(l_conv)\n",
    "            self.fpn_convs.append(fpn_conv)\n",
    "\n",
    "        # add extra conv layers (e.g., RetinaNet)\n",
    "        extra_out_levels = (\n",
    "            num_outs - self.backbone_end_level + self.start_level)\n",
    "        if extra_out_levels >= 1:\n",
    "            for i in range(extra_out_levels):\n",
    "                in_channels = (\n",
    "                    self.in_channels[self.backbone_end_level -\n",
    "                                     1] if i == 0 else out_channels)\n",
    "                extra_l_conv = ConvModule(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    norm_cfg=norm_cfg,\n",
    "                    bias=self.with_bias,\n",
    "                    act_cfg=act_cfg,\n",
    "                    inplace=False,\n",
    "                    order=self.order)\n",
    "                if self.upsample == 'deconv':\n",
    "                    upsampler_cfg_ = dict(\n",
    "                        in_channels=out_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=self.upsample_kernel,\n",
    "                        stride=2,\n",
    "                        padding=(self.upsample_kernel - 1) // 2,\n",
    "                        output_padding=(self.upsample_kernel - 1) // 2)\n",
    "                elif self.upsample == 'pixel_shuffle':\n",
    "                    upsampler_cfg_ = dict(\n",
    "                        in_channels=out_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        scale_factor=2,\n",
    "                        upsample_kernel=self.upsample_kernel)\n",
    "                elif self.upsample == 'carafe':\n",
    "                    upsampler_cfg_ = dict(\n",
    "                        channels=out_channels,\n",
    "                        scale_factor=2,\n",
    "                        **self.upsample_cfg)\n",
    "                else:\n",
    "                    # suppress warnings\n",
    "                    align_corners = (None\n",
    "                                     if self.upsample == 'nearest' else False)\n",
    "                    upsampler_cfg_ = dict(\n",
    "                        scale_factor=2,\n",
    "                        mode=self.upsample,\n",
    "                        align_corners=align_corners)\n",
    "                upsampler_cfg_['type'] = self.upsample\n",
    "                upsample_module = build_upsample_layer(upsampler_cfg_)\n",
    "                extra_fpn_conv = ConvModule(\n",
    "                    out_channels,\n",
    "                    out_channels,\n",
    "                    3,\n",
    "                    padding=1,\n",
    "                    norm_cfg=self.norm_cfg,\n",
    "                    bias=self.with_bias,\n",
    "                    act_cfg=act_cfg,\n",
    "                    inplace=False,\n",
    "                    order=self.order)\n",
    "                self.upsample_modules.append(upsample_module)\n",
    "                self.fpn_convs.append(extra_fpn_conv)\n",
    "                self.lateral_convs.append(extra_l_conv)\n",
    "\n",
    "    # default init_weights for conv(msra) and norm in ConvModule\n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize the weights of module.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "                xavier_init(m, distribution='uniform')\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, CARAFEPack):\n",
    "                m.init_weights()\n",
    "\n",
    "    def slice_as(self, src, dst):\n",
    "        \"\"\"Slice ``src`` as ``dst``\n",
    "\n",
    "        Note:\n",
    "            ``src`` should have the same or larger size than ``dst``.\n",
    "\n",
    "        Args:\n",
    "            src (torch.Tensor): Tensors to be sliced.\n",
    "            dst (torch.Tensor): ``src`` will be sliced to have the same\n",
    "                size as ``dst``.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Sliced tensor.\n",
    "        \"\"\"\n",
    "        assert (src.size(2) >= dst.size(2)) and (src.size(3) >= dst.size(3))\n",
    "        if src.size(2) == dst.size(2) and src.size(3) == dst.size(3):\n",
    "            return src\n",
    "        else:\n",
    "            return src[:, :, :dst.size(2), :dst.size(3)]\n",
    "\n",
    "    def tensor_add(self, a, b):\n",
    "        \"\"\"Add tensors ``a`` and ``b`` that might have different sizes.\"\"\"\n",
    "        if a.size() == b.size():\n",
    "            c = a + b\n",
    "        else:\n",
    "            c = a + self.slice_as(b, a)\n",
    "        return c\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward function.\"\"\"\n",
    "        assert len(inputs) == len(self.in_channels)\n",
    "\n",
    "        # build laterals\n",
    "        laterals = []\n",
    "        for i, lateral_conv in enumerate(self.lateral_convs):\n",
    "            if i <= self.backbone_end_level - self.start_level:\n",
    "                input = inputs[min(i + self.start_level, len(inputs) - 1)]\n",
    "            else:\n",
    "                input = laterals[-1]\n",
    "            lateral = lateral_conv(input)\n",
    "            laterals.append(lateral)\n",
    "\n",
    "        # build top-down path\n",
    "        for i in range(len(laterals) - 1, 0, -1):\n",
    "            if self.upsample is not None:\n",
    "                upsample_feat = self.upsample_modules[i - 1](laterals[i])\n",
    "            else:\n",
    "                upsample_feat = laterals[i]\n",
    "            laterals[i - 1] = self.tensor_add(laterals[i - 1], upsample_feat)\n",
    "#===============================improved=============================\n",
    "        used_backbone_levels = len(laterals)\n",
    "        inter_outs = [\n",
    "            self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels)\n",
    "        ]   #第一级输出，后面融合的使用append()方法\n",
    "\n",
    "        # add bottom-up path\n",
    "        #for i in range(start_level + 1, used_backbone_levels):#1，2，3\n",
    "            #inter_outs[i] = inter_outs[i] + self.downsample_convs[i-1](inter_outs[i-1])\n",
    "\n",
    "#====================================================================\n",
    "\n",
    "\n",
    "        outs = []\n",
    "        #inter_outs[0]不涉及融合，将inter_outs[0]粘贴进入元组\n",
    "        outs.append(inter_outs[0])#融合第一级输出\n",
    "        outs.extend([\n",
    "            self.pafpn_convs[i - 1](inter_outs[i])\n",
    "            for i in range(1, used_backbone_levels)#1，2，3\n",
    "        ])\n",
    "\n",
    "        return tuple(outs)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    s = 300\n",
    "    in_channels = [256, 512, 1024, 2048]\n",
    "    feat_sizes = [s // 2**i for i in range(4)]  # [600, 300, 150, 75]\n",
    "#    print(feat_sizes)\n",
    "    out_channels = 256\n",
    "    num_outs = 5\n",
    "    fpn_model = LFP(\n",
    "        in_channels = in_channels,\n",
    "        out_channels = out_channels,\n",
    "        start_level = 0,\n",
    "        num_outs = num_outs)\n",
    "    \n",
    "    inputs = [\n",
    "        torch.rand(1, in_channels[i], feat_sizes[i], feat_sizes[i])\n",
    "        for i in range(len(in_channels))]\n",
    "      \n",
    "    #print(len(inputs))\n",
    "    LFP.forward(fpn_model, inputs)\n",
    "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    #summary(fpn_model, (3, 600, 600))#输入数据 3x600x512\n",
    "    #print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
