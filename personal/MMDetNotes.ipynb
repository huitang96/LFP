{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题收集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ModuleNotFoundError: No module named 'mmcv._ext'\n",
    "\n",
    "RuntimeError: unexpected EOF, expected 9359235 more bytes. The file might be corrupted.\n",
    "\n",
    "\n",
    "OSError: /work_dirs/D2Det_detection_r50_fpn_2x/epoch_392.pth is not a checkpoint file\n",
    ":有可能是路径不对最大可能在第一个/， ./\n",
    "    \n",
    "标准：work_dirs/D2Det_detection_r50_fpn_2x/epoch_392.pth\n",
    "\n",
    "-------------------trian--------------------\n",
    "python tools/train.py configs/d2det/D2Det_detection_r50_fpn_2x.py\n",
    "\n",
    "python tools/train.py configs/retinanet/retinanet_r50_fpn_1x_coco.py\n",
    "\n",
    "\n",
    "python tools/train.py configs/ssd/ssd512_coco.py --work_dir ssd512_mm\n",
    "\n",
    "\n",
    "--------------------test--------------------\n",
    "python tools/test.py configs/d2det/D2Det_detection_r50_fpn_2x.py work_dirs/D2Det_detection_r50_fpn_2x/latest.pth --out out/aver.pkl --eval bbox --show\n",
    "\n",
    "python tools/test.py ./configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py checkpoints/latest.pth  --out out/aver.pkl --eval bbox --show\n",
    "\n",
    "\n",
    "-----------------迁移修改--------------------\n",
    "mmdet/core/evaluation/class_names.py  类别\n",
    "mmdet/datasets/coco.py   类别\n",
    "D2Det_detection_r50_fpn_2x.py  类别数  \n",
    "default_runtime.py   保存checkpoints的epochs数\n",
    "coco_detection.py   输入图片尺寸\n",
    "schedule_1x.py   训练总共epochs\n",
    "pip install -v -e .\n",
    "\n",
    "\n",
    "\n",
    "KeyError: 'ConvWS is already registered in conv layer'  原因是升级了mmcv版本    pip install mmcv==0.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 版本查看与匹配问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-4b99ca8d465b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-4b99ca8d465b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    mmdet与mmcv-full 的匹配问题\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#mmdet与mmcv-full 的匹配问题\n",
    "\n",
    "#不推荐使用mmcv  而使用mmcv-full\n",
    "\n",
    "#常用查看方法 conda list \n",
    "\n",
    "\n",
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(mmdet.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version  #indicate mmcv install successfully\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmdet/models/detectors/base.py中   修改边界框显示风格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-2-da30c29506ba>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-da30c29506ba>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    三个测试基准：mmdetection、Detectron、maskrcnn-benchmark\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "三个测试基准：mmdetection、Detectron、maskrcnn-benchmark\n",
    "\n",
    "mmdetection与Detectron相比具有3个优势 ：\n",
    "1）更高的性能（尤其是在掩模AP方面）\n",
    "2）训练速度更快\n",
    "3）高效记忆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMDetection and MMCV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MM-Detection是基于PyTorch的目标检测工具包，主要特点：\n",
    "\n",
    "(1). 模块化设计：可以通过连接不同组件容易地构建自定义的目标检测框架；\n",
    "\n",
    "(2). 支持多个流程检测框架：如RPN，Fast RCNN, Faster RCNN, Mask RCNN, RetinaNet等；\n",
    "\n",
    "(3). 高效：所有基本的bbox和掩码操作现在都在GPU上运行；\n",
    "\n",
    "(4). 重构自MMDet团队的代码库，该团队赢得了2018 COCO Detection挑战赛的冠军。\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mmdetection主要模块组成：\n",
    "\n",
    "configs：包含了很多网络配置文件，类似于caffe中的prototxt文件；\n",
    "\n",
    "mmdet：核心模块\n",
    "\n",
    "    mmdet/apis：train和inference的检测接口；\n",
    "\n",
    "    mmdet/core：anchor、bbox、evaluation等相关实现；\n",
    "\n",
    "    mmdet/datasets：数据集相关实现；\n",
    "\n",
    "    mmdet/models：各种检测网络实现函数，基类均来自于pytorch的torch.nn.Module；\n",
    "\n",
    "    mmdet/ops：roi align、roi pool等相关实现。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmdetection依赖cuda、mmcv、Cython、PyTorch、torvision：\n",
    "\n",
    "(1). cuda：想要编译mmdetection必须在本机上安装有cuda，支持在一块GPU或多块GPU上运行，支持的cuda版本包括8.0, 9.0, 10.0；\n",
    "\n",
    "(2). mmcv：是基础库也是open-mmlab项目的一部分，主要分为两个部分：一部分是和 deep learning framework无关的一些工具函数，\n",
    "比如 IO/Image/Video相关的一些操作；另一部分是为PyTorch写的一套训练工具，可以大大减少用户需要写的代码量，\n",
    "同时让整个流程的定制变得容易。mmcv仅有python的实现，它依赖numpy, pyyaml, six, addict, requests, opencv-python；\n",
    "\n",
    "(3). Cython：python库，利用python类似的语法达到接近C语言的运行速度；\n",
    "\n",
    "(4). PyTorch：由facebook开源的深度学习框架，对外提供python和C++等接口，可编译于windows, linux, mac平台：\n",
    "\n",
    "主要模块组成：\n",
    "\n",
    "aten：底层tensor库；\n",
    "\n",
    "c10：后端库，无依赖；\n",
    "\n",
    "caffe2：一种新的轻量级、模块化和可扩展的深度学习框架；\n",
    "\n",
    "torch：一个科学计算框架，支持很多机器学习算法；\n",
    "\n",
    "modules：caffe2额外实现的layer；\n",
    "\n",
    "third party：pytorch支持许多第三方库扩展，如FBGEMM、MIOpen、MKL-DNN、NNPACK、ProtoBuf、\n",
    "FFmpeg、NCCL、OpenCV、SNPE、Eigen、TensorRT、ONNX等。\n",
    "\n",
    "(5). torvision：支持流行的数据集load, 模型架构和通用的计算机视觉的图像操作，依赖PIL和torch。\n",
    "支持的图像操作包括归一化、缩放、pad、剪切、flip、旋转、仿射变换等；支持的模型架构包括\n",
    "alexnet, densenet, inception, resnet, squeezenet, vgg；\n",
    "支持的数据集包括mnist, cifar, coco, cityscapes, fakedata, stl10。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从零开始安装脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -n open-mmlab python=3.7 -y\n",
    "conda activate open-mmlab\n",
    "\n",
    "conda install -c pytorch pytorch torchvision -y\n",
    "conda install cython -y\n",
    "git clone https://github.com/open-mmlab/mmdetection.git\n",
    "cd mmdetection\n",
    "pip install -v -e .\n",
    "\n",
    "mkdir data\n",
    "ln -s $COCO_ROOT data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "环境搭建教程：\n",
    "https://my.oschina.net/u/4255345/blog/4479437"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单GPU训练\n",
    "python tools/train.py ${CONFIG_FILE}\n",
    "\n",
    "python tools/train.py chongqing_tainchi/cascade_rcnn_r50_fpn_1x.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single-gpu testing 单GPU测试\n",
    "python tools/test.py ${CONFIG_FILE} ${CHECKPOINT_FILE} [--out ${RESULT_FILE}] [--eval ${EVAL_METRICS}] [--show]\n",
    "\n",
    "    测试Faster R-CNN并显示结果\n",
    "    eg:python tools/test.py configs/faster_rcnn_r50_fpn_1x.py \\\n",
    "    checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth \\\n",
    "    --out out/resule.pkl --eval bbox --show\n",
    "        \n",
    "    测试Mask R-CNN并评估bbox和mask AP  \n",
    "    eg:python tools/test.py configs/mask_rcnn_r50_fpn_1x.py \\\n",
    "    checkpoints/mask_rcnn_r50_fpn_1x_20181010-069fa190.pth \\\n",
    "    --out results.pkl --eval bbox segm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 网络摄像头演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python demo/webcam_demo.py ${CONFIG_FILE} ${CHECKPOINT_FILE} [--device ${GPU_ID}] [--camera-id ${CAMERA-ID}] [--score-thr ${SCORE_THR}]\n",
    "\n",
    "python demo/webcam_demo.py configs/faster_rcnn_r50_fpn_1x.py \\\n",
    "    checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 分析日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python tools/analyze_logs.py plot_curve [--keys ${KEYS}] [--title ${TITLE}] [--legend ${LEGEND}] [--backend ${BACKEND}] [--style ${STYLE}] [--out ${OUT_FILE}]\n",
    "绘制分类损失\n",
    "python tools/analyze_logs.py plot_curve log.json --keys loss_cls --legend loss_cls\n",
    "绘制分类和回归损失  并保存为pdf\n",
    "python tools/analyze_logs.py plot_curve log.json --keys loss_cls loss_reg --out losses.pdf\n",
    "比较同一图中两次运行的bbox mAP\n",
    "python tools/analyze_logs.py plot_curve log1.json log2.json --keys bbox_mAP --legend run1 run2\n",
    "计算平均训练速度\n",
    "python tools/analyze_logs.py cal_train_time ${CONFIG_FILE} [--include-outliers]\n",
    "分析基于类的mAP，以更全面地了解该模型\n",
    "python coco_eval.py ${RESULT} --ann ${ANNOTATION_PATH} --types bbox --classwise\n",
    "计算给定模型的FLOP和参数\n",
    "python tools/get_flops.py ${CONFIG_FILE} [--shape ${INPUT_SHAPE}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "压缩一个模型—publish_model.py压缩模型\n",
    "python tools/publish_model.py ${INPUT_FILENAME} ${OUTPUT_FILENAME}\n",
    "    eg:python tools/publish_model.py work_dirs/faster_rcnn/latest.pth faster_rcnn_r50_fpn_1x_20190801.pth\n",
    "测试检测器的健壮性\n",
    "ROBUSTNESS_BENCHMARKING.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用自己的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_train2017.json',\n",
      "        img_prefix='data/coco/train2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_val2017.json',\n",
      "        img_prefix='data/coco/val2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_val2017.json',\n",
      "        img_prefix='data/coco/val2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=2, metric='bbox')\n",
      "checkpoint_config = dict(interval=10)\n",
      "log_config = dict(interval=2, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "model = dict(\n",
      "    type='D2Det',\n",
      "    pretrained='torchvision://resnet50',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch'),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(\n",
      "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='D2DetRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(\n",
      "                type='DeformRoIPoolingPack',\n",
      "                out_size=7,\n",
      "                sample_per_part=2,\n",
      "                out_channels=256,\n",
      "                no_trans=False,\n",
      "                group_size=1,\n",
      "                trans_std=0.1),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            with_reg=False,\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=3,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=2.0)),\n",
      "        reg_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', out_size=14, sample_num=2),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        d2det_head=dict(\n",
      "            type='D2DetHead',\n",
      "            num_convs=1,\n",
      "            in_channels=256,\n",
      "            num_classes=3,\n",
      "            norm_cfg=dict(type='GN', num_groups=36),\n",
      "            MASK_ON=False)))\n",
      "train_cfg = dict(\n",
      "    rpn=dict(\n",
      "        assigner=dict(\n",
      "            type='MaxIoUAssigner',\n",
      "            pos_iou_thr=0.7,\n",
      "            neg_iou_thr=0.3,\n",
      "            min_pos_iou=0.3,\n",
      "            ignore_iof_thr=-1),\n",
      "        sampler=dict(\n",
      "            type='RandomSampler',\n",
      "            num=256,\n",
      "            pos_fraction=0.5,\n",
      "            neg_pos_ub=-1,\n",
      "            add_gt_as_proposals=False),\n",
      "        allowed_border=0,\n",
      "        pos_weight=-1,\n",
      "        debug=False),\n",
      "    rpn_proposal=dict(\n",
      "        nms_across_levels=False,\n",
      "        nms_pre=2000,\n",
      "        nms_post=2000,\n",
      "        max_num=2000,\n",
      "        nms_thr=0.7,\n",
      "        min_bbox_size=0),\n",
      "    rcnn=dict(\n",
      "        assigner=dict(\n",
      "            type='MaxIoUAssigner',\n",
      "            pos_iou_thr=0.5,\n",
      "            neg_iou_thr=0.5,\n",
      "            min_pos_iou=0.5,\n",
      "            ignore_iof_thr=-1),\n",
      "        sampler=dict(\n",
      "            type='RandomSampler',\n",
      "            num=512,\n",
      "            pos_fraction=0.25,\n",
      "            neg_pos_ub=-1,\n",
      "            add_gt_as_proposals=True),\n",
      "        pos_radius=1,\n",
      "        pos_weight=-1,\n",
      "        max_num_reg=192,\n",
      "        mask_size=28,\n",
      "        debug=False))\n",
      "test_cfg = dict(\n",
      "    rpn=dict(\n",
      "        nms_across_levels=False,\n",
      "        nms_pre=1000,\n",
      "        nms_post=1000,\n",
      "        max_num=1000,\n",
      "        nms_thr=0.7,\n",
      "        min_bbox_size=0),\n",
      "    rcnn=dict(\n",
      "        score_thr=0.03, nms=dict(type='nms', iou_thr=0.5), max_per_img=125))\n",
      "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1800,\n",
      "    warmup_ratio=0.3333333333333333,\n",
      "    step=[80, 119])\n",
      "total_epochs = 120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run tools/print_config.py ./configs/d2det/D2Det_detection_r50_fpn_2x.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数解读"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### {model}_[model setting]_{backbone}_{neck}_[norm setting]_[misc]_[gpu x batch_per_gpu]_{schedule}_{dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{model}：faster_rcnn, mask_rcnn, retinanet, d2det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[model setting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{backbone}:r50, x101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{neck}:fpn, pafpn, nasfpn, c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[norm setting]:bn, gn, gn-head(将gn用于head部分), gn-neck, an-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[misc]:dconv, gcb, attention, albu, mstrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[gpu x batch_per_gpu]:8x2(8张GPU，每张的batch为2),单GPU时，lr/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{schedule}：1x, 2x, 20e（just for cascade）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{dataset}:coco, voc0712, wider-face, citycapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 注释解读"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dict(\n",
    "    type='MaskRCNN',  # The name of detector\n",
    "    pretrained=\n",
    "    'torchvision://resnet50',  # The ImageNet pretrained backbone to be loaded\n",
    "    backbone=dict(  # The config of backbone\n",
    "        type='ResNet',  # The type of the backbone, refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/backbones/resnet.py#L288 for more details.\n",
    "        depth=50,  # The depth of backbone, usually it is 50 or 101 for ResNet and ResNext backbones.\n",
    "        num_stages=4,  # Number of stages of the backbone.\n",
    "        out_indices=(0, 1, 2, 3),  # The index of output feature maps produced in each stages\n",
    "        frozen_stages=1,  # The weights in the first 1 stage are fronzen\n",
    "        norm_cfg=dict(  # The config of normalization layers.\n",
    "            type='BN',  # Type of norm layer, usually it is BN or GN\n",
    "            requires_grad=True),  # Whether to train the gamma and beta in BN\n",
    "        norm_eval=True,  # Whether to freeze the statistics in BN\n",
    "        style='pytorch'),  # The style of backbone, 'pytorch' means that stride 2 layers are in 3x3 conv, 'caffe' means stride 2 layers are in 1x1 convs.\n",
    "    neck=dict(\n",
    "        type='FPN',  # The neck of detector is FPN. We also support 'NASFPN', 'PAFPN', etc. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/necks/fpn.py#L10 for more details.\n",
    "        in_channels=[256, 512, 1024, 2048],  # The input channels, this is consistent with the output channels of backbone\n",
    "        out_channels=256,  # The output channels of each level of the pyramid feature map\n",
    "        num_outs=5),  # The number of output scales\n",
    "    rpn_head=dict(\n",
    "        type='RPNHead',  # The type of RPN head is 'RPNHead', we also support 'GARPNHead', etc. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/dense_heads/rpn_head.py#L12 for more details.\n",
    "        in_channels=256,  # The input channels of each input feature map, this is consistent with the output channels of neck\n",
    "        feat_channels=256,  # Feature channels of convolutional layers in the head.\n",
    "        anchor_generator=dict(  # The config of anchor generator\n",
    "            type='AnchorGenerator',  # Most of methods use AnchorGenerator, SSD Detectors uses `SSDAnchorGenerator`. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/anchor/anchor_generator.py#L10 for more details\n",
    "            scales=[8],  # Basic scale of the anchor, the area of the anchor in one position of a feature map will be scale * base_sizes\n",
    "            ratios=[0.5, 1.0, 2.0],  # The ratio between height and width.\n",
    "            strides=[4, 8, 16, 32, 64]),  # The strides of the anchor generator. This is consistent with the FPN feature strides. The strides will be taken as base_sizes if base_sizes is not set.\n",
    "        bbox_coder=dict(  # Config of box coder to encode and decode the boxes during training and testing\n",
    "            type='DeltaXYWHBBoxCoder',  # Type of box coder. 'DeltaXYWHBBoxCoder' is applied for most of methods. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/coder/delta_xywh_bbox_coder.py#L9 for more details.\n",
    "            target_means=[0.0, 0.0, 0.0, 0.0],  # The target means used to encode and decode boxes\n",
    "            target_stds=[1.0, 1.0, 1.0, 1.0]),  # The standard variance used to encode and decode boxes\n",
    "        loss_cls=dict(  # Config of loss function for the classification branch\n",
    "            type='CrossEntropyLoss',  # Type of loss for classification branch, we also support FocalLoss etc.\n",
    "            use_sigmoid=True,  # RPN usually perform two-class classification, so it usually uses sigmoid function.\n",
    "            loss_weight=1.0),  # Loss weight of the classification branch.\n",
    "        loss_bbox=dict(  # Config of loss function for the regression branch.\n",
    "            type='L1Loss',  # Type of loss, we also support many IoU Losses and smooth L1-loss, etc. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/losses/smooth_l1_loss.py#L56 for implementation.\n",
    "            loss_weight=1.0)),  # Loss weight of the regression branch.\n",
    "    roi_head=dict(  # RoIHead encapsulates the second stage of two-stage/cascade detectors.\n",
    "        type='StandardRoIHead',  # Type of the RoI head. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/roi_heads/standard_roi_head.py#L10 for implementation.\n",
    "        bbox_roi_extractor=dict(  # RoI feature extractor for bbox regression.\n",
    "            type='SingleRoIExtractor',  # Type of the RoI feature extractor, most of methods uses SingleRoIExtractor. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/roi_heads/roi_extractors/single_level.py#L10 for details.\n",
    "            roi_layer=dict(  # Config of RoI Layer\n",
    "                type='RoIAlign',  # Type of RoI Layer, DeformRoIPoolingPack and ModulatedDeformRoIPoolingPack are also supported. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/ops/roi_align/roi_align.py#L79 for details.\n",
    "                output_size=7,  # The output size of feature maps.\n",
    "                sampling_ratio=0),  # Sampling ratio when extracting the RoI features. 0 means adaptive ratio.\n",
    "            out_channels=256,  # output channels of the extracted feature.\n",
    "            featmap_strides=[4, 8, 16, 32]),  # Strides of multi-scale feature maps. It should be consistent to the architecture of the backbone.\n",
    "        bbox_head=dict(  # Config of box head in the RoIHead.\n",
    "            type='Shared2FCBBoxHead',  # Type of the bbox head, Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/roi_heads/bbox_heads/convfc_bbox_head.py#L177 for implementation details.\n",
    "            in_channels=256,  # Input channels for bbox head. This is consistent with the out_channels in roi_extractor\n",
    "            fc_out_channels=1024,  # Output feature channels of FC layers.\n",
    "            roi_feat_size=7,  # Size of RoI features\n",
    "            num_classes=80,  # Number of classes for classification\n",
    "            bbox_coder=dict(  # Box coder used in the second stage.\n",
    "                type='DeltaXYWHBBoxCoder',  # Type of box coder. 'DeltaXYWHBBoxCoder' is applied for most of methods.\n",
    "                target_means=[0.0, 0.0, 0.0, 0.0],  # Means used to encode and decode box\n",
    "                target_stds=[0.1, 0.1, 0.2, 0.2]),  # Standard variance for encoding and decoding. It is smaller since the boxes are more accurate. [0.1, 0.1, 0.2, 0.2] is a conventional setting.\n",
    "            reg_class_agnostic=False,  # Whether the regression is class agnostic.\n",
    "            loss_cls=dict(  # Config of loss function for the classification branch\n",
    "                type='CrossEntropyLoss',  # Type of loss for classification branch, we also support FocalLoss etc.\n",
    "                use_sigmoid=False,  # Whether to use sigmoid.\n",
    "                loss_weight=1.0),  # Loss weight of the classification branch.\n",
    "            loss_bbox=dict(  # Config of loss function for the regression branch.\n",
    "                type='L1Loss',  # Type of loss, we also support many IoU Losses and smooth L1-loss, etc.\n",
    "                loss_weight=1.0)),  # Loss weight of the regression branch.\n",
    "        mask_roi_extractor=dict(  # RoI feature extractor for bbox regression.\n",
    "            type='SingleRoIExtractor',  # Type of the RoI feature extractor, most of methods uses SingleRoIExtractor.\n",
    "            roi_layer=dict(  # Config of RoI Layer that extracts features for instance segmentation\n",
    "                type='RoIAlign',  # Type of RoI Layer, DeformRoIPoolingPack and ModulatedDeformRoIPoolingPack are also supported\n",
    "                output_size=14,  # The output size of feature maps.\n",
    "                sampling_ratio=0),  # Sampling ratio when extracting the RoI features.\n",
    "            out_channels=256,  # Output channels of the extracted feature.\n",
    "            featmap_strides=[4, 8, 16, 32]),  # Strides of multi-scale feature maps.\n",
    "        mask_head=dict(  # Mask prediction head\n",
    "            type='FCNMaskHead',  # Type of mask head, refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py#L21 for implementation details.\n",
    "            num_convs=4,  # Number of convolutional layers in mask head.\n",
    "            in_channels=256,  # Input channels, should be consistent with the output channels of mask roi extractor.\n",
    "            conv_out_channels=256,  # Output channels of the convolutional layer.\n",
    "            num_classes=80,  # Number of class to be segmented.\n",
    "            loss_mask=dict(  # Config of loss function for the mask branch.\n",
    "                type='CrossEntropyLoss',  # Type of loss used for segmentation\n",
    "                use_mask=True,  # Whether to only train the mask in the correct class.\n",
    "                loss_weight=1.0))))  # Loss weight of mask branch.\n",
    "train_cfg = dict(  # Config of training hyperparameters for rpn and rcnn\n",
    "    rpn=dict(  # Training config of rpn\n",
    "        assigner=dict(  # Config of assigner\n",
    "            type='MaxIoUAssigner',  # Type of assigner, MaxIoUAssigner is used for many common detectors. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/assigners/max_iou_assigner.py#L10 for more details.\n",
    "            pos_iou_thr=0.7,  # IoU >= threshold 0.7 will be taken as positive samples\n",
    "            neg_iou_thr=0.3,  # IoU < threshold 0.3 will be taken as negative samples\n",
    "            min_pos_iou=0.3,  # The minimal IoU threshold to take boxes as positive samples\n",
    "            match_low_quality=True,  # Whether to match the boxes under low quality (see API doc for more details).\n",
    "            ignore_iof_thr=-1),  # IoF threshold for ignoring bboxes\n",
    "        sampler=dict(  # Config of positive/negative sampler\n",
    "            type='RandomSampler',  # Type of sampler, PseudoSampler and other samplers are also supported. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/samplers/random_sampler.py#L8 for implementation details.\n",
    "            num=256,  # Number of samples\n",
    "            pos_fraction=0.5,  # The ratio of positive samples in the total samples.\n",
    "            neg_pos_ub=-1,  # The upper bound of negative samples based on the number of positive samples.\n",
    "            add_gt_as_proposals=False),  # Whether add GT as proposals after sampling.\n",
    "        allowed_border=-1,  # The border allowed after padding for valid anchors.\n",
    "        pos_weight=-1,  # The weight of positive samples during training.\n",
    "        debug=False),  # Whether to set the debug mode\n",
    "    rpn_proposal=dict(  # The config to generate proposals during training\n",
    "        nms_across_levels=False,  # Whether to do NMS for boxes across levels\n",
    "        nms_pre=2000,  # The number of boxes before NMS\n",
    "        nms_post=1000,  # The number of boxes to be kept by NMS\n",
    "        max_num=1000,  # The number of boxes to be used after NMS\n",
    "        nms_thr=0.7,  # The threshold to be used during NMS\n",
    "        min_bbox_size=0),  # The allowed minimal box size\n",
    "    rcnn=dict(  # The config for the roi heads.\n",
    "        assigner=dict(  # Config of assigner for second stage, this is different for that in rpn\n",
    "            type='MaxIoUAssigner',  # Type of assigner, MaxIoUAssigner is used for all roi_heads for now. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/assigners/max_iou_assigner.py#L10 for more details.\n",
    "            pos_iou_thr=0.5,  # IoU >= threshold 0.5 will be taken as positive samples\n",
    "            neg_iou_thr=0.5,  # IoU >= threshold 0.5 will be taken as positive samples\n",
    "            min_pos_iou=0.5,  # The minimal IoU threshold to take boxes as positive samples\n",
    "            match_low_quality=False,  # Whether to match the boxes under low quality (see API doc for more details).\n",
    "            ignore_iof_thr=-1),  # IoF threshold for ignoring bboxes\n",
    "        sampler=dict(\n",
    "            type='RandomSampler',  # Type of sampler, PseudoSampler and other samplers are also supported. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/samplers/random_sampler.py#L8 for implementation details.\n",
    "            num=512,  # Number of samples\n",
    "            pos_fraction=0.25,  # The ratio of positive samples in the total samples.\n",
    "            neg_pos_ub=-1,  # The upper bound of negative samples based on the number of positive samples.\n",
    "            add_gt_as_proposals=True\n",
    "        ),  # Whether add GT as proposals after sampling.\n",
    "        mask_size=28,  # Size of mask\n",
    "        pos_weight=-1,  # The weight of positive samples during training.\n",
    "        debug=False))  # Whether to set the debug mode\n",
    "test_cfg = dict(  # Config for testing hyperparameters for rpn and rcnn\n",
    "    rpn=dict(  # The config to generate proposals during testing\n",
    "        nms_across_levels=False,  # Whether to do NMS for boxes across levels\n",
    "        nms_pre=1000,  # The number of boxes before NMS\n",
    "        nms_post=1000,  # The number of boxes to be kept by NMS\n",
    "        max_num=1000,  # The number of boxes to be used after NMS\n",
    "        nms_thr=0.7,  # The threshold to be used during NMS\n",
    "        min_bbox_size=0),  # The allowed minimal box size\n",
    "    rcnn=dict(  # The config for the roi heads.\n",
    "        score_thr=0.05,  # Threshold to filter out boxes\n",
    "        nms=dict(  # Config of nms in the second stage\n",
    "            type='nms',  # Type of nms\n",
    "            iou_thr=0.5),  # NMS threshold\n",
    "        max_per_img=100,  # Max number of detections of each image\n",
    "        mask_thr_binary=0.5))  # Threshold of mask prediction\n",
    "dataset_type = 'CocoDataset'  # Dataset type, this will be used to define the dataset\n",
    "data_root = 'data/coco/'  # Root path of data\n",
    "img_norm_cfg = dict(  # Image normalization config to normalize the input images\n",
    "    mean=[123.675, 116.28, 103.53],  # Mean values used to pre-training the pre-trained backbone models\n",
    "    std=[58.395, 57.12, 57.375],  # Standard variance used to pre-training the pre-trained backbone models\n",
    "    to_rgb=True\n",
    ")  # The channel orders of image used to pre-training the pre-trained backbone models\n",
    "train_pipeline = [  # Training pipeline\n",
    "    dict(type='LoadImageFromFile'),  # First pipeline to load images from file path\n",
    "    dict(\n",
    "        type='LoadAnnotations',  # Second pipeline to load annotations for current image\n",
    "        with_bbox=True,  # Whether to use bounding box, True for detection\n",
    "        with_mask=True,  # Whether to use instance mask, True for instance segmentation\n",
    "        poly2mask=False),  # Whether to convert the polygon mask to instance mask, set False for acceleration and to save memory\n",
    "    dict(\n",
    "        type='Resize',  # Augmentation pipeline that resize the images and their annotations\n",
    "        img_scale=(1333, 800),  # The largest scale of image\n",
    "        keep_ratio=True\n",
    "    ),  # whether to keep the ratio between height and width.\n",
    "    dict(\n",
    "        type='RandomFlip',  # Augmentation pipeline that flip the images and their annotations\n",
    "        flip_ratio=0.5),  # The ratio or probability to flip\n",
    "    dict(\n",
    "        type='Normalize',  # Augmentation pipeline that normalize the input images\n",
    "        mean=[123.675, 116.28, 103.53],  # These keys are the same of img_norm_cfg since the\n",
    "        std=[58.395, 57.12, 57.375],  # keys of img_norm_cfg are used here as arguments\n",
    "        to_rgb=True),\n",
    "    dict(\n",
    "        type='Pad',  # Padding config\n",
    "        size_divisor=32),  # The number the padded images should be divisible\n",
    "    dict(type='DefaultFormatBundle'),  # Default format bundle to gather data in the pipeline\n",
    "    dict(\n",
    "        type='Collect',  # Pipeline that decides which keys in the data should be passed to the detector\n",
    "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),  # First pipeline to load images from file path\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',  # An encapsulation that encapsulates the testing augmentations\n",
    "        img_scale=(1333, 800),  # Decides the largest scale for testing, used for the Resize pipeline\n",
    "        flip=False,  # Whether to flip images during testing\n",
    "        transforms=[\n",
    "            dict(type='Resize',  # Use resize augmentation\n",
    "                 keep_ratio=True),  # Whether to keep the ratio between height and width, the img_scale set here will be supressed by the img_scale set above.\n",
    "            dict(type='RandomFlip'),  # Thought RandomFlip is added in pipeline, it is not used because flip=False\n",
    "            dict(\n",
    "                type='Normalize',  # Normalization config, the values are from img_norm_cfg\n",
    "                mean=[123.675, 116.28, 103.53],\n",
    "                std=[58.395, 57.12, 57.375],\n",
    "                to_rgb=True),\n",
    "            dict(\n",
    "                type='Pad',  # Padding config to pad images divisable by 32.\n",
    "                size_divisor=32),\n",
    "            dict(\n",
    "                type='ImageToTensor',  # convert image to tensor\n",
    "                keys=['img']),\n",
    "            dict(\n",
    "                type='Collect',  # Collect pipeline that collect necessary keys for testing.\n",
    "                keys=['img'])\n",
    "        ])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=2,  # Batch size of a single GPU\n",
    "    workers_per_gpu=2,  # Worker to pre-fetch data for each single GPU\n",
    "    train=dict(  # Train dataset config\n",
    "        type='CocoDataset',  # Type of dataset, refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/coco.py#L19 for details.\n",
    "        ann_file='data/coco/annotations/instances_train2017.json',  # Path of annotation file\n",
    "        img_prefix='data/coco/train2017/',  # Prefix of image path\n",
    "        pipeline=[  # pipeline, this is passed by the train_pipeline created before.\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(\n",
    "                type='LoadAnnotations',\n",
    "                with_bbox=True,\n",
    "                with_mask=True,\n",
    "                poly2mask=False),\n",
    "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
    "            dict(type='RandomFlip', flip_ratio=0.5),\n",
    "            dict(\n",
    "                type='Normalize',\n",
    "                mean=[123.675, 116.28, 103.53],\n",
    "                std=[58.395, 57.12, 57.375],\n",
    "                to_rgb=True),\n",
    "            dict(type='Pad', size_divisor=32),\n",
    "            dict(type='DefaultFormatBundle'),\n",
    "            dict(\n",
    "                type='Collect',\n",
    "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
    "        ]),\n",
    "    val=dict(  # Validation dataset config\n",
    "        type='CocoDataset',\n",
    "        ann_file='data/coco/annotations/instances_val2017.json',\n",
    "        img_prefix='data/coco/val2017/',\n",
    "        pipeline=[  # Pipeline is passed by test_pipeline created before\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(\n",
    "                type='MultiScaleFlipAug',\n",
    "                img_scale=(1333, 800),\n",
    "                flip=False,\n",
    "                transforms=[\n",
    "                    dict(type='Resize', keep_ratio=True),\n",
    "                    dict(type='RandomFlip'),\n",
    "                    dict(\n",
    "                        type='Normalize',\n",
    "                        mean=[123.675, 116.28, 103.53],\n",
    "                        std=[58.395, 57.12, 57.375],\n",
    "                        to_rgb=True),\n",
    "                    dict(type='Pad', size_divisor=32),\n",
    "                    dict(type='ImageToTensor', keys=['img']),\n",
    "                    dict(type='Collect', keys=['img'])\n",
    "                ])\n",
    "        ]),\n",
    "    test=dict(  # Test dataset config, modify the ann_file for test-dev/test submission\n",
    "        type='CocoDataset',\n",
    "        ann_file='data/coco/annotations/instances_val2017.json',\n",
    "        img_prefix='data/coco/val2017/',\n",
    "        pipeline=[  # Pipeline is passed by test_pipeline created before\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(\n",
    "                type='MultiScaleFlipAug',\n",
    "                img_scale=(1333, 800),\n",
    "                flip=False,\n",
    "                transforms=[\n",
    "                    dict(type='Resize', keep_ratio=True),\n",
    "                    dict(type='RandomFlip'),\n",
    "                    dict(\n",
    "                        type='Normalize',\n",
    "                        mean=[123.675, 116.28, 103.53],\n",
    "                        std=[58.395, 57.12, 57.375],\n",
    "                        to_rgb=True),\n",
    "                    dict(type='Pad', size_divisor=32),\n",
    "                    dict(type='ImageToTensor', keys=['img']),\n",
    "                    dict(type='Collect', keys=['img'])\n",
    "                ])\n",
    "        ],\n",
    "        samples_per_gpu=2  # Batch size of a single GPU used in testing\n",
    "        ))\n",
    "evaluation = dict(  # The config to build the evaluation hook, refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/evaluation/eval_hooks.py#L7 for more details.\n",
    "    interval=1,  # Evaluation interval\n",
    "    metric=['bbox', 'segm'])  # Metrics used during evaluation\n",
    "optimizer = dict(  # Config used to build optimizer, support all the optimizers in PyTorch whose arguments are also the same as those in PyTorch\n",
    "    type='SGD',  # Type of optimizers, refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/optimizer/default_constructor.py#L13 for more details\n",
    "    lr=0.02,  # Learning rate of optimizers, see detail usages of the parameters in the documentaion of PyTorch\n",
    "    momentum=0.9,  # Momentum\n",
    "    weight_decay=0.0001)  # Weight decay of SGD\n",
    "optimizer_config = dict(  # Config used to build the optimizer hook, refer to https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/optimizer.py#L8 for implementation details.\n",
    "    grad_clip=None)  # Most of the methods do not use gradient clip\n",
    "lr_config = dict(  # Learning rate scheduler config used to register LrUpdater hook\n",
    "    policy='step',  # The policy of scheduler, also support CosineAnnealing, Cyclic, etc. Refer to details of supported LrUpdater from https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py#L9.\n",
    "    warmup='linear',  # The warmup policy, also support `exp` and `constant`.\n",
    "    warmup_iters=500,  # The number of iterations for warmup\n",
    "    warmup_ratio=\n",
    "    0.001,  # The ratio of the starting learning rate used for warmup\n",
    "    step=[8, 11])  # Steps to decay the learning rate\n",
    "total_epochs = 12  # Total epochs to train the model\n",
    "checkpoint_config = dict(  # Config to set the checkpoint hook, Refer to https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/checkpoint.py for implementation.\n",
    "    interval=1)  # The save interval is 1\n",
    "log_config = dict(  # config to register logger hook\n",
    "    interval=50,  # Interval to print the log\n",
    "    hooks=[\n",
    "        # dict(type='TensorboardLoggerHook')  # The Tensorboard logger is also supported\n",
    "        dict(type='TextLoggerHook')\n",
    "    ])  # The logger used to record the training process.\n",
    "dist_params = dict(backend='nccl')  # Parameters to setup distributed training, the port can also be set.\n",
    "log_level = 'INFO'  # The level of logging.\n",
    "load_from = None  # load models as a pre-trained model from a given path. This will not resume training.\n",
    "resume_from = None  # Resume checkpoints from a given path, the training will be resumed from the epoch when the checkpoint's is saved.\n",
    "workflow = [('train', 1)]  # Workflow for runner. [('train', 1)] means there is only one workflow and the workflow named 'train' is executed once. The workflow trains the model by 12 epochs according to the total_epochs.\n",
    "work_dir = 'work_dir'  # Directory to save the model checkpoints and logs for the current experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用组件进行模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在原始open-mmlab基础上复现D2Det算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开发新的组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据管道图"
   ]
  },
  {
   "attachments": {
    "%E6%95%B0%E6%8D%AE%E7%AE%A1%E9%81%93%E5%9B%BE.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![%E6%95%B0%E6%8D%AE%E7%AE%A1%E9%81%93%E5%9B%BE.jpg](attachment:%E6%95%B0%E6%8D%AE%E7%AE%A1%E9%81%93%E5%9B%BE.jpg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "在MMDetection中，模型组件基本上分为4种类型\n",
    "\n",
    "    骨干网：通常是FCN网络，用于提取特征图，例如ResNet\n",
    "    \n",
    "    颈部：骨干和头部之间的部分，例如FPN，ASPP\n",
    "    \n",
    "    头部：用于特定任务的部分，例如bbox预测和蒙版预测\n",
    "    \n",
    "    roi提取器：用于从要素地图中提取要素的部分，例如RoI Align\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
