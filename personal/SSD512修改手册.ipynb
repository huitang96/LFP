{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "单阶段和二阶段目标检测方法模型表征图，\n",
    "以及各模块主要有什么\n",
    "one-stage和two-stage模型表征的异同\n",
    "</div><i class=\"fa fa-lightbulb-o \"></i>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "如果我们做的是Single-stage detector\n",
    "我们关注的文件夹是backbones，necks，dense_heads\n",
    "如果我们做的是Two-stage detector\n",
    "我们关注的文件夹是backbones，necks，dense_heads，roi_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmdetection/configs/base/default_runtime.py\n",
    "\n",
    "checkpoint_config = dict(interval=1)# 每1个epoch存储一次模型\n",
    "# yapf:disable\n",
    "log_config = dict(\n",
    "    interval=50,# 每50个batch输出一次信息\n",
    "    hooks=[\n",
    "        dict(type='TextLoggerHook'), # 控制台输出信息的风格\n",
    "        # dict(type='TensorboardLoggerHook')\n",
    "    ])\n",
    "# yapf:enable\n",
    "dist_params = dict(backend='nccl')# 分布式参数\n",
    "log_level = 'INFO'#日志等级\n",
    "load_from = None# 加载模型的路径，None表示从预训练模型加载，还可从代码更改为不加载\n",
    "resume_from = None# 恢复训练模型的路径\n",
    "workflow = [('train', 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmdetection/configs/base/schedules/\n",
    "\n",
    "schedule_1x.py，schedule_2x.py，schedule_20e.py\n",
    "1x 表示12个epoch\n",
    "2x 表示24个epoch\n",
    "20e表示 20 个epochs ，通常 cascade模型中采用\n",
    "\n",
    "\n",
    "# optimizer\n",
    "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)# 优化参数，lr为学习率，momentum为动量因子，weight_decay为权重衰减因子\n",
    "optimizer_config = dict(grad_clip=None)# 梯度均衡参数\n",
    "# learning policy 学习率策略\n",
    "lr_config = dict(\n",
    "    policy='step',# 优化策略\n",
    "    warmup='linear',# 初始的学习率增加的策略，linear为线性增加\n",
    "    warmup_iters=500,# 在初始的500次迭代中学习率逐渐增加\n",
    "    warmup_ratio=0.001,# 起始的学习率\n",
    "    step=[8, 11])# 在第8和11个epoch时降低学习率\n",
    "total_epochs = 12 # 最大epoch数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model settings\n",
    "\n",
    "\n",
    "input_size = 300\n",
    "model = dict(\n",
    "    type='SingleStageDetector',# model类型\n",
    "    pretrained='open-mmlab://vgg16_caffe',# 预训练模型：VGG16_caffe\n",
    "    backbone=dict(\n",
    "        type='SSDVGG',# backbone类型\n",
    "        input_size=input_size,\n",
    "        depth=16,\n",
    "        with_last_pool=False,\n",
    "        ceil_mode=True,\n",
    "        out_indices=(3, 4),\n",
    "        out_feature_indices=(22, 34),\n",
    "        l2_norm_scale=20),\n",
    "    neck=None,\n",
    "    bbox_head=dict(\n",
    "        type='SSDHead',\n",
    "        in_channels=(512, 1024, 512, 256, 256, 256),#输入通道\n",
    "        num_classes=80,\n",
    "        anchor_generator=dict(\n",
    "            type='SSDAnchorGenerator',\n",
    "            scale_major=False,\n",
    "            input_size=input_size,\n",
    "            basesize_ratio_range=(0.15, 0.9),\n",
    "            strides=[8, 16, 32, 64, 100, 300],# 在每个特征层对应于原图的步长\n",
    "            ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]]),#每个特征层对应先验框（prior box）的数量 是 [4,6,6,6,4,4]\n",
    "        bbox_coder=dict(\n",
    "            type='DeltaXYWHBBoxCoder',\n",
    "            target_means=[.0, .0, .0, .0],\n",
    "            target_stds=[0.1, 0.1, 0.2, 0.2])))\n",
    "cudnn_benchmark = True\n",
    "train_cfg = dict(\n",
    "    assigner=dict(\n",
    "        type='MaxIoUAssigner',\n",
    "        pos_iou_thr=0.5,# 正样本的iou阈值\n",
    "        neg_iou_thr=0.5,# 负样本的iou阈值\n",
    "        min_pos_iou=0.,# 正样本的iou最小值。如果assign给ground truth的anchors中最大的IOU小于0，则忽略所有的anchors，否则保留最大IOU的anchor\n",
    "        ignore_iof_thr=-1, #忽略bbox的阈值，当ground truth中包含需要忽略的bbox时使用，-1表示不忽略\n",
    "        gt_max_assign_all=False),\n",
    "    smoothl1_beta=1.,# 平滑L1系数\n",
    "    allowed_border=-1, # 允许在bbox周围外扩一定的像素\n",
    "    pos_weight=-1,\n",
    "    neg_pos_ratio=3,\n",
    "    debug=False)# debug模式\n",
    "test_cfg = dict(\n",
    "    nms=dict(type='nms', iou_thr=0.45),\n",
    "    min_bbox_size=0,\n",
    "    score_thr=0.02,\n",
    "    max_per_img=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_base_ = [\n",
    "    '../_base_/models/ssd300.py', '../_base_/datasets/coco_detection.py',\n",
    "    '../_base_/schedules/schedule_2x.py', '../_base_/default_runtime.py'\n",
    "]\n",
    "# dataset settings\n",
    "dataset_type = 'CocoDataset' #数据集的类型\n",
    "data_root = 'data/coco/'#数据集的根目录\n",
    "# # 将输入图像norm，减去均值mean并除以方差std，to_rgb表示将bgr转为rgb\n",
    "\n",
    "# 归一化再标准化的做法\n",
    "# img = (img/255 - mean) / std\n",
    "\n",
    "#只做标准化的做法\n",
    "#img = (img - mean)/std\n",
    "\n",
    "\n",
    "#  caffe 的img_norm方法是\n",
    "#img_norm_cfg = dict(\n",
    "#    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
    "# PyTorch 中经常看到的是下面这样\n",
    "#img_norm_cfg = dict(\n",
    "#    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "\n",
    "img_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[1, 1, 1], to_rgb=True)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile', to_float32=True),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(\n",
    "        type='PhotoMetricDistortion',#PhotoMetricDistortion 数据增强，可以调整包括亮度，对比度，饱和度,色调\n",
    "        brightness_delta=32,\n",
    "        contrast_range=(0.5, 1.5),\n",
    "        saturation_range=(0.5, 1.5),\n",
    "        hue_delta=18),\n",
    "    dict(\n",
    "        type='Expand',\n",
    "        mean=img_norm_cfg['mean'],\n",
    "        to_rgb=img_norm_cfg['to_rgb'],\n",
    "        ratio_range=(1, 4)),\n",
    "    dict(\n",
    "        type='MinIoURandomCrop',\n",
    "        min_ious=(0.1, 0.3, 0.5, 0.7, 0.9),\n",
    "        min_crop_size=0.3),\n",
    "    dict(type='Resize', img_scale=(300, 300), keep_ratio=False),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(300, 300),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=False),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=8,# 每个gpu分配的样本数量\n",
    "    workers_per_gpu=3,# 每个gpu分配的线程数\n",
    "    train=dict(\n",
    "        _delete_=True,\n",
    "        type='RepeatDataset',\n",
    "        times=5,\n",
    "        dataset=dict(\n",
    "            type=dataset_type,\n",
    "            ann_file=data_root + 'annotations/instances_train2017.json',\n",
    "            img_prefix=data_root + 'train2017/',\n",
    "            pipeline=train_pipeline)),\n",
    "    val=dict(pipeline=test_pipeline),\n",
    "    test=dict(pipeline=test_pipeline))\n",
    "# optimizer\n",
    "optimizer = dict(type='SGD', lr=2e-3, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer_config = dict(_delete_=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/1Projects/mmdetection-master/mmdet/models/backbones/ssd_vgg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_root_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBACKBONES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "# %run mmdet/models/backbones/ssd_vgg.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
